<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="ukr">
<DOC id="L0C049PA1" lang="ukr" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="10311" raw_text_md5="ff8d7aaebfa42e780531c0371970c481">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="44">
<ORIGINAL_TEXT>New coronavirus threat galvanizes scientists</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="3">New</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="5" end_char="15">coronavirus</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="17" end_char="22">threat</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="24" end_char="33">galvanizes</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="35" end_char="44">scientists</TOKEN>
</SEG>
<SEG id="segment-1" start_char="48" end_char="219">
<ORIGINAL_TEXT>Barely 1 month after Chinese health authorities reported the first cases of a mysterious new pneumonia in the city of Wuhan, the world may be on the cusp of a new pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="48" end_char="53">Barely</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="55" end_char="55">1</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="57" end_char="61">month</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="63" end_char="67">after</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="69" end_char="75">Chinese</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="77" end_char="82">health</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="84" end_char="94">authorities</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="96" end_char="103">reported</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="105" end_char="107">the</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="109" end_char="113">first</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="115" end_char="119">cases</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="121" end_char="122">of</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="124" end_char="124">a</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="126" end_char="135">mysterious</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="137" end_char="139">new</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="141" end_char="149">pneumonia</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="151" end_char="152">in</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="154" end_char="156">the</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="158" end_char="161">city</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="163" end_char="164">of</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="166" end_char="170">Wuhan</TOKEN>
<TOKEN id="token-1-21" pos="punct" morph="none" start_char="171" end_char="171">,</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="173" end_char="175">the</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="177" end_char="181">world</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="183" end_char="185">may</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="187" end_char="188">be</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="190" end_char="191">on</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="193" end_char="195">the</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="197" end_char="200">cusp</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="202" end_char="203">of</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="205" end_char="205">a</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="207" end_char="209">new</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="211" end_char="218">pandemic</TOKEN>
<TOKEN id="token-1-33" pos="punct" morph="none" start_char="219" end_char="219">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="221" end_char="222">
<ORIGINAL_TEXT>As</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="221" end_char="222">As</TOKEN>
</SEG>
<SEG id="segment-3" start_char="225" end_char="231">
<ORIGINAL_TEXT>Science</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="225" end_char="231">Science</TOKEN>
</SEG>
<SEG id="segment-4" start_char="234" end_char="439">
<ORIGINAL_TEXT>went to press, the number of confirmed cases of the novel coronavirus, dubbed 2019-nCoV, had shot up to more than 4500, most of them in mainland China but more than 80 in 17 other countries and territories.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="234" end_char="237">went</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="239" end_char="240">to</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="242" end_char="246">press</TOKEN>
<TOKEN id="token-4-3" pos="punct" morph="none" start_char="247" end_char="247">,</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="249" end_char="251">the</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="253" end_char="258">number</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="260" end_char="261">of</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="263" end_char="271">confirmed</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="273" end_char="277">cases</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="279" end_char="280">of</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="282" end_char="284">the</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="286" end_char="290">novel</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="292" end_char="302">coronavirus</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="303" end_char="303">,</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="305" end_char="310">dubbed</TOKEN>
<TOKEN id="token-4-15" pos="unknown" morph="none" start_char="312" end_char="320">2019-nCoV</TOKEN>
<TOKEN id="token-4-16" pos="punct" morph="none" start_char="321" end_char="321">,</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="323" end_char="325">had</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="327" end_char="330">shot</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="332" end_char="333">up</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="335" end_char="336">to</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="338" end_char="341">more</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="343" end_char="346">than</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="348" end_char="351">4500</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="352" end_char="352">,</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="354" end_char="357">most</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="359" end_char="360">of</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="362" end_char="365">them</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="367" end_char="368">in</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="370" end_char="377">mainland</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="379" end_char="383">China</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="385" end_char="387">but</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="389" end_char="392">more</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="394" end_char="397">than</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="399" end_char="400">80</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="402" end_char="403">in</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="405" end_char="406">17</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="408" end_char="412">other</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="414" end_char="422">countries</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="424" end_char="426">and</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="428" end_char="438">territories</TOKEN>
<TOKEN id="token-4-41" pos="punct" morph="none" start_char="439" end_char="439">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="441" end_char="569">
<ORIGINAL_TEXT>China has quarantined 35 million people in Wuhan and several other cities in a desperate attempt to slow the spread of the virus.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="441" end_char="445">China</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="447" end_char="449">has</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="451" end_char="461">quarantined</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="463" end_char="464">35</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="466" end_char="472">million</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="474" end_char="479">people</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="481" end_char="482">in</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="484" end_char="488">Wuhan</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="490" end_char="492">and</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="494" end_char="500">several</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="502" end_char="506">other</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="508" end_char="513">cities</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="515" end_char="516">in</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="518" end_char="518">a</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="520" end_char="528">desperate</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="530" end_char="536">attempt</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="538" end_char="539">to</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="541" end_char="544">slow</TOKEN>
<TOKEN id="token-5-18" pos="word" morph="none" start_char="546" end_char="548">the</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="550" end_char="555">spread</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="557" end_char="558">of</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="560" end_char="562">the</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="564" end_char="568">virus</TOKEN>
<TOKEN id="token-5-23" pos="punct" morph="none" start_char="569" end_char="569">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="571" end_char="679">
<ORIGINAL_TEXT>But as the case numbers keep soaring, the realization has set in that it may be too late to have much impact.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="571" end_char="573">But</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="575" end_char="576">as</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="578" end_char="580">the</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="582" end_char="585">case</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="587" end_char="593">numbers</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="595" end_char="598">keep</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="600" end_char="606">soaring</TOKEN>
<TOKEN id="token-6-7" pos="punct" morph="none" start_char="607" end_char="607">,</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="609" end_char="611">the</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="613" end_char="623">realization</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="625" end_char="627">has</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="629" end_char="631">set</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="633" end_char="634">in</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="636" end_char="639">that</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="641" end_char="642">it</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="644" end_char="646">may</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="648" end_char="649">be</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="651" end_char="653">too</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="655" end_char="658">late</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="660" end_char="661">to</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="663" end_char="666">have</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="668" end_char="671">much</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="673" end_char="678">impact</TOKEN>
<TOKEN id="token-6-23" pos="punct" morph="none" start_char="679" end_char="679">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="682" end_char="757">
<ORIGINAL_TEXT>Even seasoned epidemiologists are astonished at the virus's dizzying spread.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="682" end_char="685">Even</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="687" end_char="694">seasoned</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="696" end_char="710">epidemiologists</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="712" end_char="714">are</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="716" end_char="725">astonished</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="727" end_char="728">at</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="730" end_char="732">the</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="734" end_char="740">virus's</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="742" end_char="749">dizzying</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="751" end_char="756">spread</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="757" end_char="757">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="759" end_char="885">
<ORIGINAL_TEXT>Early estimates of the number of infected people—thought to far exceed the number of confirmed cases—became obsolete overnight.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="759" end_char="763">Early</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="765" end_char="773">estimates</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="775" end_char="776">of</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="778" end_char="780">the</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="782" end_char="787">number</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="789" end_char="790">of</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="792" end_char="799">infected</TOKEN>
<TOKEN id="token-8-7" pos="unknown" morph="none" start_char="801" end_char="814">people—thought</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="816" end_char="817">to</TOKEN>
<TOKEN id="token-8-9" pos="word" morph="none" start_char="819" end_char="821">far</TOKEN>
<TOKEN id="token-8-10" pos="word" morph="none" start_char="823" end_char="828">exceed</TOKEN>
<TOKEN id="token-8-11" pos="word" morph="none" start_char="830" end_char="832">the</TOKEN>
<TOKEN id="token-8-12" pos="word" morph="none" start_char="834" end_char="839">number</TOKEN>
<TOKEN id="token-8-13" pos="word" morph="none" start_char="841" end_char="842">of</TOKEN>
<TOKEN id="token-8-14" pos="word" morph="none" start_char="844" end_char="852">confirmed</TOKEN>
<TOKEN id="token-8-15" pos="unknown" morph="none" start_char="854" end_char="865">cases—became</TOKEN>
<TOKEN id="token-8-16" pos="word" morph="none" start_char="867" end_char="874">obsolete</TOKEN>
<TOKEN id="token-8-17" pos="word" morph="none" start_char="876" end_char="884">overnight</TOKEN>
<TOKEN id="token-8-18" pos="punct" morph="none" start_char="885" end_char="885">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="887" end_char="1084">
<ORIGINAL_TEXT>"Our original results are NO LONGER VALID," University of Hong Kong epidemiologist Gabriel Leung tweeted on 22 January, 1 day after his group had posted its first mathematical model of the epidemic.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="887" end_char="887">"</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="888" end_char="890">Our</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="892" end_char="899">original</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="901" end_char="907">results</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="909" end_char="911">are</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="913" end_char="914">NO</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="916" end_char="921">LONGER</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="923" end_char="927">VALID</TOKEN>
<TOKEN id="token-9-8" pos="punct" morph="none" start_char="928" end_char="929">,"</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="931" end_char="940">University</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="942" end_char="943">of</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="945" end_char="948">Hong</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="950" end_char="953">Kong</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="955" end_char="968">epidemiologist</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="970" end_char="976">Gabriel</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="978" end_char="982">Leung</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="984" end_char="990">tweeted</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="992" end_char="993">on</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="995" end_char="996">22</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="998" end_char="1004">January</TOKEN>
<TOKEN id="token-9-20" pos="punct" morph="none" start_char="1005" end_char="1005">,</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1007" end_char="1007">1</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1009" end_char="1011">day</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1013" end_char="1017">after</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1019" end_char="1021">his</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1023" end_char="1027">group</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1029" end_char="1031">had</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1033" end_char="1038">posted</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1040" end_char="1042">its</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1044" end_char="1048">first</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1050" end_char="1061">mathematical</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1063" end_char="1067">model</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1069" end_char="1070">of</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1072" end_char="1074">the</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1076" end_char="1083">epidemic</TOKEN>
<TOKEN id="token-9-35" pos="punct" morph="none" start_char="1084" end_char="1084">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1086" end_char="1207">
<ORIGINAL_TEXT>Leung is now estimating that Wuhan alone had 43,590 infections by 25 January—and that the number is doubling every 6 days.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1086" end_char="1090">Leung</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1092" end_char="1093">is</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1095" end_char="1097">now</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1099" end_char="1108">estimating</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1110" end_char="1113">that</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1115" end_char="1119">Wuhan</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1121" end_char="1125">alone</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1127" end_char="1129">had</TOKEN>
<TOKEN id="token-10-8" pos="unknown" morph="none" start_char="1131" end_char="1136">43,590</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1138" end_char="1147">infections</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1149" end_char="1150">by</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1152" end_char="1153">25</TOKEN>
<TOKEN id="token-10-12" pos="unknown" morph="none" start_char="1155" end_char="1165">January—and</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1167" end_char="1170">that</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1172" end_char="1174">the</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1176" end_char="1181">number</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1183" end_char="1184">is</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1186" end_char="1193">doubling</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1195" end_char="1199">every</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1201" end_char="1201">6</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1203" end_char="1206">days</TOKEN>
<TOKEN id="token-10-21" pos="punct" morph="none" start_char="1207" end_char="1207">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1209" end_char="1238">
<ORIGINAL_TEXT>"How widespread does this go?"</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="punct" morph="none" start_char="1209" end_char="1209">"</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1210" end_char="1212">How</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1214" end_char="1223">widespread</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1225" end_char="1228">does</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1230" end_char="1233">this</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1235" end_char="1236">go</TOKEN>
<TOKEN id="token-11-6" pos="punct" morph="none" start_char="1237" end_char="1238">?"</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1240" end_char="1300">
<ORIGINAL_TEXT>asks Marion Koopmans, a virologist at Erasmus Medical Center.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1240" end_char="1243">asks</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1245" end_char="1250">Marion</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1252" end_char="1259">Koopmans</TOKEN>
<TOKEN id="token-12-3" pos="punct" morph="none" start_char="1260" end_char="1260">,</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1262" end_char="1262">a</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1264" end_char="1273">virologist</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1275" end_char="1276">at</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1278" end_char="1284">Erasmus</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1286" end_char="1292">Medical</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1294" end_char="1299">Center</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1300" end_char="1300">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1302" end_char="1336">
<ORIGINAL_TEXT>"This deserves our full attention."</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1302" end_char="1302">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1303" end_char="1306">This</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1308" end_char="1315">deserves</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1317" end_char="1319">our</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1321" end_char="1324">full</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1326" end_char="1334">attention</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="1335" end_char="1336">."</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1339" end_char="1524">
<ORIGINAL_TEXT>Early this week, the World Health Organization (WHO) had not yet declared the outbreak a Public Health Emergency of International Concern (PHEIC), the loudest alarm the agency can sound.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1339" end_char="1343">Early</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1345" end_char="1348">this</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1350" end_char="1353">week</TOKEN>
<TOKEN id="token-14-3" pos="punct" morph="none" start_char="1354" end_char="1354">,</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1356" end_char="1358">the</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1360" end_char="1364">World</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1366" end_char="1371">Health</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1373" end_char="1384">Organization</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="1386" end_char="1386">(</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1387" end_char="1389">WHO</TOKEN>
<TOKEN id="token-14-10" pos="punct" morph="none" start_char="1390" end_char="1390">)</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1392" end_char="1394">had</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1396" end_char="1398">not</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1400" end_char="1402">yet</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1404" end_char="1411">declared</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1413" end_char="1415">the</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1417" end_char="1424">outbreak</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1426" end_char="1426">a</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1428" end_char="1433">Public</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1435" end_char="1440">Health</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1442" end_char="1450">Emergency</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1452" end_char="1453">of</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1455" end_char="1467">International</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1469" end_char="1475">Concern</TOKEN>
<TOKEN id="token-14-24" pos="punct" morph="none" start_char="1477" end_char="1477">(</TOKEN>
<TOKEN id="token-14-25" pos="word" morph="none" start_char="1478" end_char="1482">PHEIC</TOKEN>
<TOKEN id="token-14-26" pos="punct" morph="none" start_char="1483" end_char="1484">),</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1486" end_char="1488">the</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1490" end_char="1496">loudest</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1498" end_char="1502">alarm</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1504" end_char="1506">the</TOKEN>
<TOKEN id="token-14-31" pos="word" morph="none" start_char="1508" end_char="1513">agency</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1515" end_char="1517">can</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1519" end_char="1523">sound</TOKEN>
<TOKEN id="token-14-34" pos="punct" morph="none" start_char="1524" end_char="1524">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1526" end_char="1748">
<ORIGINAL_TEXT>In meetings on 22 and 23 January, a special WHO committee that includes Koopmans was divided on whether a PHEIC was warranted, in part because there was no evidence the disease was spreading between people outside of China.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1526" end_char="1527">In</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1529" end_char="1536">meetings</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1538" end_char="1539">on</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1541" end_char="1542">22</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1544" end_char="1546">and</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1548" end_char="1549">23</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1551" end_char="1557">January</TOKEN>
<TOKEN id="token-15-7" pos="punct" morph="none" start_char="1558" end_char="1558">,</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1560" end_char="1560">a</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1562" end_char="1568">special</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1570" end_char="1572">WHO</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1574" end_char="1582">committee</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1584" end_char="1587">that</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1589" end_char="1596">includes</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1598" end_char="1605">Koopmans</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1607" end_char="1609">was</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1611" end_char="1617">divided</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1619" end_char="1620">on</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1622" end_char="1628">whether</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1630" end_char="1630">a</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1632" end_char="1636">PHEIC</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1638" end_char="1640">was</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1642" end_char="1650">warranted</TOKEN>
<TOKEN id="token-15-23" pos="punct" morph="none" start_char="1651" end_char="1651">,</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="1653" end_char="1654">in</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="1656" end_char="1659">part</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="1661" end_char="1667">because</TOKEN>
<TOKEN id="token-15-27" pos="word" morph="none" start_char="1669" end_char="1673">there</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="1675" end_char="1677">was</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="1679" end_char="1680">no</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="1682" end_char="1689">evidence</TOKEN>
<TOKEN id="token-15-31" pos="word" morph="none" start_char="1691" end_char="1693">the</TOKEN>
<TOKEN id="token-15-32" pos="word" morph="none" start_char="1695" end_char="1701">disease</TOKEN>
<TOKEN id="token-15-33" pos="word" morph="none" start_char="1703" end_char="1705">was</TOKEN>
<TOKEN id="token-15-34" pos="word" morph="none" start_char="1707" end_char="1715">spreading</TOKEN>
<TOKEN id="token-15-35" pos="word" morph="none" start_char="1717" end_char="1723">between</TOKEN>
<TOKEN id="token-15-36" pos="word" morph="none" start_char="1725" end_char="1730">people</TOKEN>
<TOKEN id="token-15-37" pos="word" morph="none" start_char="1732" end_char="1738">outside</TOKEN>
<TOKEN id="token-15-38" pos="word" morph="none" start_char="1740" end_char="1741">of</TOKEN>
<TOKEN id="token-15-39" pos="word" morph="none" start_char="1743" end_char="1747">China</TOKEN>
<TOKEN id="token-15-40" pos="punct" morph="none" start_char="1748" end_char="1748">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1750" end_char="1864">
<ORIGINAL_TEXT>But by 28 January, several countries had reported local human-to-human transmission, which may change the equation.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1750" end_char="1752">But</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1754" end_char="1755">by</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="1757" end_char="1758">28</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1760" end_char="1766">January</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="1767" end_char="1767">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1769" end_char="1775">several</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1777" end_char="1785">countries</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1787" end_char="1789">had</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1791" end_char="1798">reported</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1800" end_char="1804">local</TOKEN>
<TOKEN id="token-16-10" pos="unknown" morph="none" start_char="1806" end_char="1819">human-to-human</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1821" end_char="1832">transmission</TOKEN>
<TOKEN id="token-16-12" pos="punct" morph="none" start_char="1833" end_char="1833">,</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="1835" end_char="1839">which</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1841" end_char="1843">may</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1845" end_char="1850">change</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1852" end_char="1854">the</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="1856" end_char="1863">equation</TOKEN>
<TOKEN id="token-16-18" pos="punct" morph="none" start_char="1864" end_char="1864">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1867" end_char="1889">
<ORIGINAL_TEXT>Get the latest issue of</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1867" end_char="1869">Get</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1871" end_char="1873">the</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1875" end_char="1880">latest</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1882" end_char="1886">issue</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1888" end_char="1889">of</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1892" end_char="1898">
<ORIGINAL_TEXT>Science</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1892" end_char="1898">Science</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1901" end_char="1923">
<ORIGINAL_TEXT>delivered right to you!</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1901" end_char="1909">delivered</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1911" end_char="1915">right</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1917" end_char="1918">to</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1920" end_char="1922">you</TOKEN>
<TOKEN id="token-19-4" pos="punct" morph="none" start_char="1923" end_char="1923">!</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1926" end_char="2056">
<ORIGINAL_TEXT>So far 2019-nCoV appears to be milder than its cousin, severe acute respiratory syndrome (SARS), which had a mortality rate of 10%.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1926" end_char="1927">So</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1929" end_char="1931">far</TOKEN>
<TOKEN id="token-20-2" pos="unknown" morph="none" start_char="1933" end_char="1941">2019-nCoV</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1943" end_char="1949">appears</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1951" end_char="1952">to</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="1954" end_char="1955">be</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="1957" end_char="1962">milder</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="1964" end_char="1967">than</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="1969" end_char="1971">its</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="1973" end_char="1978">cousin</TOKEN>
<TOKEN id="token-20-10" pos="punct" morph="none" start_char="1979" end_char="1979">,</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="1981" end_char="1986">severe</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="1988" end_char="1992">acute</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="1994" end_char="2004">respiratory</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2006" end_char="2013">syndrome</TOKEN>
<TOKEN id="token-20-15" pos="punct" morph="none" start_char="2015" end_char="2015">(</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2016" end_char="2019">SARS</TOKEN>
<TOKEN id="token-20-17" pos="punct" morph="none" start_char="2020" end_char="2021">),</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2023" end_char="2027">which</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2029" end_char="2031">had</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2033" end_char="2033">a</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2035" end_char="2043">mortality</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2045" end_char="2048">rate</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2050" end_char="2051">of</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2053" end_char="2054">10</TOKEN>
<TOKEN id="token-20-25" pos="punct" morph="none" start_char="2055" end_char="2056">%.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2058" end_char="2100">
<ORIGINAL_TEXT>Only 106 deaths have been recorded to date.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2058" end_char="2061">Only</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2063" end_char="2065">106</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2067" end_char="2072">deaths</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2074" end_char="2077">have</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2079" end_char="2082">been</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2084" end_char="2091">recorded</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2093" end_char="2094">to</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2096" end_char="2099">date</TOKEN>
<TOKEN id="token-21-8" pos="punct" morph="none" start_char="2100" end_char="2100">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2102" end_char="2171">
<ORIGINAL_TEXT>But hundreds more people are seriously ill, and their fate is unclear.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2102" end_char="2104">But</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2106" end_char="2113">hundreds</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2115" end_char="2118">more</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2120" end_char="2125">people</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2127" end_char="2129">are</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2131" end_char="2139">seriously</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2141" end_char="2143">ill</TOKEN>
<TOKEN id="token-22-7" pos="punct" morph="none" start_char="2144" end_char="2144">,</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2146" end_char="2148">and</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2150" end_char="2154">their</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="2156" end_char="2159">fate</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="2161" end_char="2162">is</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2164" end_char="2170">unclear</TOKEN>
<TOKEN id="token-22-13" pos="punct" morph="none" start_char="2171" end_char="2171">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2173" end_char="2209">
<ORIGINAL_TEXT>And countless other questions remain.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2173" end_char="2175">And</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2177" end_char="2185">countless</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2187" end_char="2191">other</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2193" end_char="2201">questions</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2203" end_char="2208">remain</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="2209" end_char="2209">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2211" end_char="2340">
<ORIGINAL_TEXT>Scientists don't know how long the incubation period lasts or whether infected people who show no symptoms can transmit the virus.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2211" end_char="2220">Scientists</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2222" end_char="2226">don't</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2228" end_char="2231">know</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2233" end_char="2235">how</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2237" end_char="2240">long</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2242" end_char="2244">the</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="2246" end_char="2255">incubation</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2257" end_char="2262">period</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2264" end_char="2268">lasts</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2270" end_char="2271">or</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2273" end_char="2279">whether</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2281" end_char="2288">infected</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2290" end_char="2295">people</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2297" end_char="2299">who</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2301" end_char="2304">show</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2306" end_char="2307">no</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2309" end_char="2316">symptoms</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2318" end_char="2320">can</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2322" end_char="2329">transmit</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2331" end_char="2333">the</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2335" end_char="2339">virus</TOKEN>
<TOKEN id="token-24-21" pos="punct" morph="none" start_char="2340" end_char="2340">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2342" end_char="2475">
<ORIGINAL_TEXT>China's state-run news agency Xinhua reported on 26 January that a seemingly healthy man appeared to have infected "a few colleagues."</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2342" end_char="2348">China's</TOKEN>
<TOKEN id="token-25-1" pos="unknown" morph="none" start_char="2350" end_char="2358">state-run</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2360" end_char="2363">news</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="2365" end_char="2370">agency</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2372" end_char="2377">Xinhua</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2379" end_char="2386">reported</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2388" end_char="2389">on</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="2391" end_char="2392">26</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2394" end_char="2400">January</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2402" end_char="2405">that</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2407" end_char="2407">a</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2409" end_char="2417">seemingly</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2419" end_char="2425">healthy</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2427" end_char="2429">man</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2431" end_char="2438">appeared</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2440" end_char="2441">to</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2443" end_char="2446">have</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2448" end_char="2455">infected</TOKEN>
<TOKEN id="token-25-18" pos="punct" morph="none" start_char="2457" end_char="2457">"</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2458" end_char="2458">a</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2460" end_char="2462">few</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="2464" end_char="2473">colleagues</TOKEN>
<TOKEN id="token-25-22" pos="punct" morph="none" start_char="2474" end_char="2475">."</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2477" end_char="2581">
<ORIGINAL_TEXT>If asymptomatic people frequently infect others, it could vastly complicate efforts to contain 2019-nCoV.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2477" end_char="2478">If</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2480" end_char="2491">asymptomatic</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2493" end_char="2498">people</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2500" end_char="2509">frequently</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2511" end_char="2516">infect</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2518" end_char="2523">others</TOKEN>
<TOKEN id="token-26-6" pos="punct" morph="none" start_char="2524" end_char="2524">,</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2526" end_char="2527">it</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2529" end_char="2533">could</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2535" end_char="2540">vastly</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2542" end_char="2551">complicate</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2553" end_char="2559">efforts</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2561" end_char="2562">to</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2564" end_char="2570">contain</TOKEN>
<TOKEN id="token-26-14" pos="unknown" morph="none" start_char="2572" end_char="2580">2019-nCoV</TOKEN>
<TOKEN id="token-26-15" pos="punct" morph="none" start_char="2581" end_char="2581">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2584" end_char="2801">
<ORIGINAL_TEXT>The virus's explosive spread has been met by an unprecedented rush by scientists to uncover its origins, find treatments, and develop vaccines that could save millions of lives if the world really does face a pandemic.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2584" end_char="2586">The</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="2588" end_char="2594">virus's</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="2596" end_char="2604">explosive</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="2606" end_char="2611">spread</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="2613" end_char="2615">has</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="2617" end_char="2620">been</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="2622" end_char="2624">met</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="2626" end_char="2627">by</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="2629" end_char="2630">an</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="2632" end_char="2644">unprecedented</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="2646" end_char="2649">rush</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="2651" end_char="2652">by</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="2654" end_char="2663">scientists</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="2665" end_char="2666">to</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="2668" end_char="2674">uncover</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="2676" end_char="2678">its</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="2680" end_char="2686">origins</TOKEN>
<TOKEN id="token-27-17" pos="punct" morph="none" start_char="2687" end_char="2687">,</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="2689" end_char="2692">find</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="2694" end_char="2703">treatments</TOKEN>
<TOKEN id="token-27-20" pos="punct" morph="none" start_char="2704" end_char="2704">,</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="2706" end_char="2708">and</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="2710" end_char="2716">develop</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="2718" end_char="2725">vaccines</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="2727" end_char="2730">that</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="2732" end_char="2736">could</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="2738" end_char="2741">save</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="2743" end_char="2750">millions</TOKEN>
<TOKEN id="token-27-28" pos="word" morph="none" start_char="2752" end_char="2753">of</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="2755" end_char="2759">lives</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="2761" end_char="2762">if</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="2764" end_char="2766">the</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="2768" end_char="2772">world</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="2774" end_char="2779">really</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="2781" end_char="2784">does</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="2786" end_char="2789">face</TOKEN>
<TOKEN id="token-27-36" pos="word" morph="none" start_char="2791" end_char="2791">a</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="2793" end_char="2800">pandemic</TOKEN>
<TOKEN id="token-27-38" pos="punct" morph="none" start_char="2801" end_char="2801">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="2803" end_char="2906">
<ORIGINAL_TEXT>Here are some of the ways researchers are attempting to better understand 2019-nCoV and reduce its harm.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="2803" end_char="2806">Here</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="2808" end_char="2810">are</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="2812" end_char="2815">some</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="2817" end_char="2818">of</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="2820" end_char="2822">the</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="2824" end_char="2827">ways</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="2829" end_char="2839">researchers</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="2841" end_char="2843">are</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="2845" end_char="2854">attempting</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="2856" end_char="2857">to</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="2859" end_char="2864">better</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="2866" end_char="2875">understand</TOKEN>
<TOKEN id="token-28-12" pos="unknown" morph="none" start_char="2877" end_char="2885">2019-nCoV</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="2887" end_char="2889">and</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="2891" end_char="2896">reduce</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="2898" end_char="2900">its</TOKEN>
<TOKEN id="token-28-16" pos="word" morph="none" start_char="2902" end_char="2905">harm</TOKEN>
<TOKEN id="token-28-17" pos="punct" morph="none" start_char="2906" end_char="2906">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="2909" end_char="2938">
<ORIGINAL_TEXT>Where Did the Virus Come From?</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="2909" end_char="2913">Where</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="2915" end_char="2917">Did</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="2919" end_char="2921">the</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="2923" end_char="2927">Virus</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="2929" end_char="2932">Come</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="2934" end_char="2937">From</TOKEN>
<TOKEN id="token-29-6" pos="punct" morph="none" start_char="2938" end_char="2938">?</TOKEN>
</SEG>
<SEG id="segment-30" start_char="2942" end_char="3003">
<ORIGINAL_TEXT>Almost certainly from animals, but when and how are mysteries.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2942" end_char="2947">Almost</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2949" end_char="2957">certainly</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2959" end_char="2962">from</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2964" end_char="2970">animals</TOKEN>
<TOKEN id="token-30-4" pos="punct" morph="none" start_char="2971" end_char="2971">,</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2973" end_char="2975">but</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2977" end_char="2980">when</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2982" end_char="2984">and</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2986" end_char="2988">how</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2990" end_char="2992">are</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2994" end_char="3002">mysteries</TOKEN>
<TOKEN id="token-30-11" pos="punct" morph="none" start_char="3003" end_char="3003">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="3005" end_char="3054">
<ORIGINAL_TEXT>Genetic analyses are starting to yield some clues.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="3005" end_char="3011">Genetic</TOKEN>
<TOKEN id="token-31-1" pos="word" morph="none" start_char="3013" end_char="3020">analyses</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="3022" end_char="3024">are</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="3026" end_char="3033">starting</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="3035" end_char="3036">to</TOKEN>
<TOKEN id="token-31-5" pos="word" morph="none" start_char="3038" end_char="3042">yield</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="3044" end_char="3047">some</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="3049" end_char="3053">clues</TOKEN>
<TOKEN id="token-31-8" pos="punct" morph="none" start_char="3054" end_char="3054">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="3056" end_char="3134">
<ORIGINAL_TEXT>Chinese researchers first shared a genomic sequence of 2019-nCoV on 11 January.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="3056" end_char="3062">Chinese</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="3064" end_char="3074">researchers</TOKEN>
<TOKEN id="token-32-2" pos="word" morph="none" start_char="3076" end_char="3080">first</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="3082" end_char="3087">shared</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="3089" end_char="3089">a</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="3091" end_char="3097">genomic</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="3099" end_char="3106">sequence</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="3108" end_char="3109">of</TOKEN>
<TOKEN id="token-32-8" pos="unknown" morph="none" start_char="3111" end_char="3119">2019-nCoV</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="3121" end_char="3122">on</TOKEN>
<TOKEN id="token-32-10" pos="word" morph="none" start_char="3124" end_char="3125">11</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="3127" end_char="3133">January</TOKEN>
<TOKEN id="token-32-12" pos="punct" morph="none" start_char="3134" end_char="3134">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="3136" end_char="3265">
<ORIGINAL_TEXT>Labs in China and abroad have since announced nearly three dozen additional sequences of the virus—"a stellar job," Koopmans says.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="3136" end_char="3139">Labs</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="3141" end_char="3142">in</TOKEN>
<TOKEN id="token-33-2" pos="word" morph="none" start_char="3144" end_char="3148">China</TOKEN>
<TOKEN id="token-33-3" pos="word" morph="none" start_char="3150" end_char="3152">and</TOKEN>
<TOKEN id="token-33-4" pos="word" morph="none" start_char="3154" end_char="3159">abroad</TOKEN>
<TOKEN id="token-33-5" pos="word" morph="none" start_char="3161" end_char="3164">have</TOKEN>
<TOKEN id="token-33-6" pos="word" morph="none" start_char="3166" end_char="3170">since</TOKEN>
<TOKEN id="token-33-7" pos="word" morph="none" start_char="3172" end_char="3180">announced</TOKEN>
<TOKEN id="token-33-8" pos="word" morph="none" start_char="3182" end_char="3187">nearly</TOKEN>
<TOKEN id="token-33-9" pos="word" morph="none" start_char="3189" end_char="3193">three</TOKEN>
<TOKEN id="token-33-10" pos="word" morph="none" start_char="3195" end_char="3199">dozen</TOKEN>
<TOKEN id="token-33-11" pos="word" morph="none" start_char="3201" end_char="3210">additional</TOKEN>
<TOKEN id="token-33-12" pos="word" morph="none" start_char="3212" end_char="3220">sequences</TOKEN>
<TOKEN id="token-33-13" pos="word" morph="none" start_char="3222" end_char="3223">of</TOKEN>
<TOKEN id="token-33-14" pos="word" morph="none" start_char="3225" end_char="3227">the</TOKEN>
<TOKEN id="token-33-15" pos="unknown" morph="none" start_char="3229" end_char="3236">virus—"a</TOKEN>
<TOKEN id="token-33-16" pos="word" morph="none" start_char="3238" end_char="3244">stellar</TOKEN>
<TOKEN id="token-33-17" pos="word" morph="none" start_char="3246" end_char="3248">job</TOKEN>
<TOKEN id="token-33-18" pos="punct" morph="none" start_char="3249" end_char="3250">,"</TOKEN>
<TOKEN id="token-33-19" pos="word" morph="none" start_char="3252" end_char="3259">Koopmans</TOKEN>
<TOKEN id="token-33-20" pos="word" morph="none" start_char="3261" end_char="3264">says</TOKEN>
<TOKEN id="token-33-21" pos="punct" morph="none" start_char="3265" end_char="3265">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="3268" end_char="3471">
<ORIGINAL_TEXT>A team led by Shi Zheng-Li of the Wuhan Institute of Virology reported on 23 January that 2019-nCoV's sequence was 96.2% identical to that of a bat coronavirus and 79.5% identical to the SARS coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="3268" end_char="3268">A</TOKEN>
<TOKEN id="token-34-1" pos="word" morph="none" start_char="3270" end_char="3273">team</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="3275" end_char="3277">led</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="3279" end_char="3280">by</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="3282" end_char="3284">Shi</TOKEN>
<TOKEN id="token-34-5" pos="unknown" morph="none" start_char="3286" end_char="3293">Zheng-Li</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="3295" end_char="3296">of</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="3298" end_char="3300">the</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="3302" end_char="3306">Wuhan</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="3308" end_char="3316">Institute</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="3318" end_char="3319">of</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="3321" end_char="3328">Virology</TOKEN>
<TOKEN id="token-34-12" pos="word" morph="none" start_char="3330" end_char="3337">reported</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="3339" end_char="3340">on</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="3342" end_char="3343">23</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="3345" end_char="3351">January</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="3353" end_char="3356">that</TOKEN>
<TOKEN id="token-34-17" pos="unknown" morph="none" start_char="3358" end_char="3368">2019-nCoV's</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="3370" end_char="3377">sequence</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="3379" end_char="3381">was</TOKEN>
<TOKEN id="token-34-20" pos="unknown" morph="none" start_char="3383" end_char="3386">96.2</TOKEN>
<TOKEN id="token-34-21" pos="punct" morph="none" start_char="3387" end_char="3387">%</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="3389" end_char="3397">identical</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="3399" end_char="3400">to</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="3402" end_char="3405">that</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="3407" end_char="3408">of</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="3410" end_char="3410">a</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="3412" end_char="3414">bat</TOKEN>
<TOKEN id="token-34-28" pos="word" morph="none" start_char="3416" end_char="3426">coronavirus</TOKEN>
<TOKEN id="token-34-29" pos="word" morph="none" start_char="3428" end_char="3430">and</TOKEN>
<TOKEN id="token-34-30" pos="unknown" morph="none" start_char="3432" end_char="3435">79.5</TOKEN>
<TOKEN id="token-34-31" pos="punct" morph="none" start_char="3436" end_char="3436">%</TOKEN>
<TOKEN id="token-34-32" pos="word" morph="none" start_char="3438" end_char="3446">identical</TOKEN>
<TOKEN id="token-34-33" pos="word" morph="none" start_char="3448" end_char="3449">to</TOKEN>
<TOKEN id="token-34-34" pos="word" morph="none" start_char="3451" end_char="3453">the</TOKEN>
<TOKEN id="token-34-35" pos="word" morph="none" start_char="3455" end_char="3458">SARS</TOKEN>
<TOKEN id="token-34-36" pos="word" morph="none" start_char="3460" end_char="3470">coronavirus</TOKEN>
<TOKEN id="token-34-37" pos="punct" morph="none" start_char="3471" end_char="3471">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="3473" end_char="3603">
<ORIGINAL_TEXT>That doesn't mean 2019-nCoV jumped directly from bats to humans, says evolutionary biologist Kristian Andersen of Scripps Research.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="3473" end_char="3476">That</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="3478" end_char="3484">doesn't</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="3486" end_char="3489">mean</TOKEN>
<TOKEN id="token-35-3" pos="unknown" morph="none" start_char="3491" end_char="3499">2019-nCoV</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="3501" end_char="3506">jumped</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="3508" end_char="3515">directly</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="3517" end_char="3520">from</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="3522" end_char="3525">bats</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="3527" end_char="3528">to</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="3530" end_char="3535">humans</TOKEN>
<TOKEN id="token-35-10" pos="punct" morph="none" start_char="3536" end_char="3536">,</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="3538" end_char="3541">says</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="3543" end_char="3554">evolutionary</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="3556" end_char="3564">biologist</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="3566" end_char="3573">Kristian</TOKEN>
<TOKEN id="token-35-15" pos="word" morph="none" start_char="3575" end_char="3582">Andersen</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="3584" end_char="3585">of</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="3587" end_char="3593">Scripps</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="3595" end_char="3602">Research</TOKEN>
<TOKEN id="token-35-19" pos="punct" morph="none" start_char="3603" end_char="3603">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="3605" end_char="3703">
<ORIGINAL_TEXT>SARS, for example, probably moved from bats to civets—sold as a delicacy in many markets—to humans.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="3605" end_char="3608">SARS</TOKEN>
<TOKEN id="token-36-1" pos="punct" morph="none" start_char="3609" end_char="3609">,</TOKEN>
<TOKEN id="token-36-2" pos="word" morph="none" start_char="3611" end_char="3613">for</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="3615" end_char="3621">example</TOKEN>
<TOKEN id="token-36-4" pos="punct" morph="none" start_char="3622" end_char="3622">,</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="3624" end_char="3631">probably</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="3633" end_char="3637">moved</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="3639" end_char="3642">from</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="3644" end_char="3647">bats</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="3649" end_char="3650">to</TOKEN>
<TOKEN id="token-36-10" pos="unknown" morph="none" start_char="3652" end_char="3662">civets—sold</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="3664" end_char="3665">as</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="3667" end_char="3667">a</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="3669" end_char="3676">delicacy</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="3678" end_char="3679">in</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="3681" end_char="3684">many</TOKEN>
<TOKEN id="token-36-16" pos="unknown" morph="none" start_char="3686" end_char="3695">markets—to</TOKEN>
<TOKEN id="token-36-17" pos="word" morph="none" start_char="3697" end_char="3702">humans</TOKEN>
<TOKEN id="token-36-18" pos="punct" morph="none" start_char="3703" end_char="3703">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="3706" end_char="3898">
<ORIGINAL_TEXT>From the start, the Huanan Seafood Wholesale Market in Wuhan—which sold mammals as well as fish—was considered a likely source of the outbreak because most of the early patients had visited it.</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="3706" end_char="3709">From</TOKEN>
<TOKEN id="token-37-1" pos="word" morph="none" start_char="3711" end_char="3713">the</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="3715" end_char="3719">start</TOKEN>
<TOKEN id="token-37-3" pos="punct" morph="none" start_char="3720" end_char="3720">,</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="3722" end_char="3724">the</TOKEN>
<TOKEN id="token-37-5" pos="word" morph="none" start_char="3726" end_char="3731">Huanan</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="3733" end_char="3739">Seafood</TOKEN>
<TOKEN id="token-37-7" pos="word" morph="none" start_char="3741" end_char="3749">Wholesale</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="3751" end_char="3756">Market</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="3758" end_char="3759">in</TOKEN>
<TOKEN id="token-37-10" pos="unknown" morph="none" start_char="3761" end_char="3771">Wuhan—which</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="3773" end_char="3776">sold</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="3778" end_char="3784">mammals</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="3786" end_char="3787">as</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="3789" end_char="3792">well</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="3794" end_char="3795">as</TOKEN>
<TOKEN id="token-37-16" pos="unknown" morph="none" start_char="3797" end_char="3804">fish—was</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="3806" end_char="3815">considered</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="3817" end_char="3817">a</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="3819" end_char="3824">likely</TOKEN>
<TOKEN id="token-37-20" pos="word" morph="none" start_char="3826" end_char="3831">source</TOKEN>
<TOKEN id="token-37-21" pos="word" morph="none" start_char="3833" end_char="3834">of</TOKEN>
<TOKEN id="token-37-22" pos="word" morph="none" start_char="3836" end_char="3838">the</TOKEN>
<TOKEN id="token-37-23" pos="word" morph="none" start_char="3840" end_char="3847">outbreak</TOKEN>
<TOKEN id="token-37-24" pos="word" morph="none" start_char="3849" end_char="3855">because</TOKEN>
<TOKEN id="token-37-25" pos="word" morph="none" start_char="3857" end_char="3860">most</TOKEN>
<TOKEN id="token-37-26" pos="word" morph="none" start_char="3862" end_char="3863">of</TOKEN>
<TOKEN id="token-37-27" pos="word" morph="none" start_char="3865" end_char="3867">the</TOKEN>
<TOKEN id="token-37-28" pos="word" morph="none" start_char="3869" end_char="3873">early</TOKEN>
<TOKEN id="token-37-29" pos="word" morph="none" start_char="3875" end_char="3882">patients</TOKEN>
<TOKEN id="token-37-30" pos="word" morph="none" start_char="3884" end_char="3886">had</TOKEN>
<TOKEN id="token-37-31" pos="word" morph="none" start_char="3888" end_char="3894">visited</TOKEN>
<TOKEN id="token-37-32" pos="word" morph="none" start_char="3896" end_char="3897">it</TOKEN>
<TOKEN id="token-37-33" pos="punct" morph="none" start_char="3898" end_char="3898">.</TOKEN>
</SEG>
<SEG id="segment-38" start_char="3900" end_char="4098">
<ORIGINAL_TEXT>On 27 January, Xinhua reported that researchers have found evidence of the new coronavirus in 33 of 585 environmental samples taken at the market on 1 January—the day it was closed—and on 12 January.</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="word" morph="none" start_char="3900" end_char="3901">On</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="3903" end_char="3904">27</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="3906" end_char="3912">January</TOKEN>
<TOKEN id="token-38-3" pos="punct" morph="none" start_char="3913" end_char="3913">,</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="3915" end_char="3920">Xinhua</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="3922" end_char="3929">reported</TOKEN>
<TOKEN id="token-38-6" pos="word" morph="none" start_char="3931" end_char="3934">that</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="3936" end_char="3946">researchers</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="3948" end_char="3951">have</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="3953" end_char="3957">found</TOKEN>
<TOKEN id="token-38-10" pos="word" morph="none" start_char="3959" end_char="3966">evidence</TOKEN>
<TOKEN id="token-38-11" pos="word" morph="none" start_char="3968" end_char="3969">of</TOKEN>
<TOKEN id="token-38-12" pos="word" morph="none" start_char="3971" end_char="3973">the</TOKEN>
<TOKEN id="token-38-13" pos="word" morph="none" start_char="3975" end_char="3977">new</TOKEN>
<TOKEN id="token-38-14" pos="word" morph="none" start_char="3979" end_char="3989">coronavirus</TOKEN>
<TOKEN id="token-38-15" pos="word" morph="none" start_char="3991" end_char="3992">in</TOKEN>
<TOKEN id="token-38-16" pos="word" morph="none" start_char="3994" end_char="3995">33</TOKEN>
<TOKEN id="token-38-17" pos="word" morph="none" start_char="3997" end_char="3998">of</TOKEN>
<TOKEN id="token-38-18" pos="word" morph="none" start_char="4000" end_char="4002">585</TOKEN>
<TOKEN id="token-38-19" pos="word" morph="none" start_char="4004" end_char="4016">environmental</TOKEN>
<TOKEN id="token-38-20" pos="word" morph="none" start_char="4018" end_char="4024">samples</TOKEN>
<TOKEN id="token-38-21" pos="word" morph="none" start_char="4026" end_char="4030">taken</TOKEN>
<TOKEN id="token-38-22" pos="word" morph="none" start_char="4032" end_char="4033">at</TOKEN>
<TOKEN id="token-38-23" pos="word" morph="none" start_char="4035" end_char="4037">the</TOKEN>
<TOKEN id="token-38-24" pos="word" morph="none" start_char="4039" end_char="4044">market</TOKEN>
<TOKEN id="token-38-25" pos="word" morph="none" start_char="4046" end_char="4047">on</TOKEN>
<TOKEN id="token-38-26" pos="word" morph="none" start_char="4049" end_char="4049">1</TOKEN>
<TOKEN id="token-38-27" pos="unknown" morph="none" start_char="4051" end_char="4061">January—the</TOKEN>
<TOKEN id="token-38-28" pos="word" morph="none" start_char="4063" end_char="4065">day</TOKEN>
<TOKEN id="token-38-29" pos="word" morph="none" start_char="4067" end_char="4068">it</TOKEN>
<TOKEN id="token-38-30" pos="word" morph="none" start_char="4070" end_char="4072">was</TOKEN>
<TOKEN id="token-38-31" pos="unknown" morph="none" start_char="4074" end_char="4083">closed—and</TOKEN>
<TOKEN id="token-38-32" pos="word" morph="none" start_char="4085" end_char="4086">on</TOKEN>
<TOKEN id="token-38-33" pos="word" morph="none" start_char="4088" end_char="4089">12</TOKEN>
<TOKEN id="token-38-34" pos="word" morph="none" start_char="4091" end_char="4097">January</TOKEN>
<TOKEN id="token-38-35" pos="punct" morph="none" start_char="4098" end_char="4098">.</TOKEN>
</SEG>
<SEG id="segment-39" start_char="4100" end_char="4188">
<ORIGINAL_TEXT>They all came from the western end, which had a concentration of booths selling wildlife.</ORIGINAL_TEXT>
<TOKEN id="token-39-0" pos="word" morph="none" start_char="4100" end_char="4103">They</TOKEN>
<TOKEN id="token-39-1" pos="word" morph="none" start_char="4105" end_char="4107">all</TOKEN>
<TOKEN id="token-39-2" pos="word" morph="none" start_char="4109" end_char="4112">came</TOKEN>
<TOKEN id="token-39-3" pos="word" morph="none" start_char="4114" end_char="4117">from</TOKEN>
<TOKEN id="token-39-4" pos="word" morph="none" start_char="4119" end_char="4121">the</TOKEN>
<TOKEN id="token-39-5" pos="word" morph="none" start_char="4123" end_char="4129">western</TOKEN>
<TOKEN id="token-39-6" pos="word" morph="none" start_char="4131" end_char="4133">end</TOKEN>
<TOKEN id="token-39-7" pos="punct" morph="none" start_char="4134" end_char="4134">,</TOKEN>
<TOKEN id="token-39-8" pos="word" morph="none" start_char="4136" end_char="4140">which</TOKEN>
<TOKEN id="token-39-9" pos="word" morph="none" start_char="4142" end_char="4144">had</TOKEN>
<TOKEN id="token-39-10" pos="word" morph="none" start_char="4146" end_char="4146">a</TOKEN>
<TOKEN id="token-39-11" pos="word" morph="none" start_char="4148" end_char="4160">concentration</TOKEN>
<TOKEN id="token-39-12" pos="word" morph="none" start_char="4162" end_char="4163">of</TOKEN>
<TOKEN id="token-39-13" pos="word" morph="none" start_char="4165" end_char="4170">booths</TOKEN>
<TOKEN id="token-39-14" pos="word" morph="none" start_char="4172" end_char="4178">selling</TOKEN>
<TOKEN id="token-39-15" pos="word" morph="none" start_char="4180" end_char="4187">wildlife</TOKEN>
<TOKEN id="token-39-16" pos="punct" morph="none" start_char="4188" end_char="4188">.</TOKEN>
</SEG>
<SEG id="segment-40" start_char="4191" end_char="4383">
<ORIGINAL_TEXT>That indicates the market played a role in spreading the virus, says Daniel Lucey, an infectious disease specialist at Georgetown University—but he says other data suggest it wasn't the origin.</ORIGINAL_TEXT>
<TOKEN id="token-40-0" pos="word" morph="none" start_char="4191" end_char="4194">That</TOKEN>
<TOKEN id="token-40-1" pos="word" morph="none" start_char="4196" end_char="4204">indicates</TOKEN>
<TOKEN id="token-40-2" pos="word" morph="none" start_char="4206" end_char="4208">the</TOKEN>
<TOKEN id="token-40-3" pos="word" morph="none" start_char="4210" end_char="4215">market</TOKEN>
<TOKEN id="token-40-4" pos="word" morph="none" start_char="4217" end_char="4222">played</TOKEN>
<TOKEN id="token-40-5" pos="word" morph="none" start_char="4224" end_char="4224">a</TOKEN>
<TOKEN id="token-40-6" pos="word" morph="none" start_char="4226" end_char="4229">role</TOKEN>
<TOKEN id="token-40-7" pos="word" morph="none" start_char="4231" end_char="4232">in</TOKEN>
<TOKEN id="token-40-8" pos="word" morph="none" start_char="4234" end_char="4242">spreading</TOKEN>
<TOKEN id="token-40-9" pos="word" morph="none" start_char="4244" end_char="4246">the</TOKEN>
<TOKEN id="token-40-10" pos="word" morph="none" start_char="4248" end_char="4252">virus</TOKEN>
<TOKEN id="token-40-11" pos="punct" morph="none" start_char="4253" end_char="4253">,</TOKEN>
<TOKEN id="token-40-12" pos="word" morph="none" start_char="4255" end_char="4258">says</TOKEN>
<TOKEN id="token-40-13" pos="word" morph="none" start_char="4260" end_char="4265">Daniel</TOKEN>
<TOKEN id="token-40-14" pos="word" morph="none" start_char="4267" end_char="4271">Lucey</TOKEN>
<TOKEN id="token-40-15" pos="punct" morph="none" start_char="4272" end_char="4272">,</TOKEN>
<TOKEN id="token-40-16" pos="word" morph="none" start_char="4274" end_char="4275">an</TOKEN>
<TOKEN id="token-40-17" pos="word" morph="none" start_char="4277" end_char="4286">infectious</TOKEN>
<TOKEN id="token-40-18" pos="word" morph="none" start_char="4288" end_char="4294">disease</TOKEN>
<TOKEN id="token-40-19" pos="word" morph="none" start_char="4296" end_char="4305">specialist</TOKEN>
<TOKEN id="token-40-20" pos="word" morph="none" start_char="4307" end_char="4308">at</TOKEN>
<TOKEN id="token-40-21" pos="word" morph="none" start_char="4310" end_char="4319">Georgetown</TOKEN>
<TOKEN id="token-40-22" pos="unknown" morph="none" start_char="4321" end_char="4334">University—but</TOKEN>
<TOKEN id="token-40-23" pos="word" morph="none" start_char="4336" end_char="4337">he</TOKEN>
<TOKEN id="token-40-24" pos="word" morph="none" start_char="4339" end_char="4342">says</TOKEN>
<TOKEN id="token-40-25" pos="word" morph="none" start_char="4344" end_char="4348">other</TOKEN>
<TOKEN id="token-40-26" pos="word" morph="none" start_char="4350" end_char="4353">data</TOKEN>
<TOKEN id="token-40-27" pos="word" morph="none" start_char="4355" end_char="4361">suggest</TOKEN>
<TOKEN id="token-40-28" pos="word" morph="none" start_char="4363" end_char="4364">it</TOKEN>
<TOKEN id="token-40-29" pos="word" morph="none" start_char="4366" end_char="4371">wasn't</TOKEN>
<TOKEN id="token-40-30" pos="word" morph="none" start_char="4373" end_char="4375">the</TOKEN>
<TOKEN id="token-40-31" pos="word" morph="none" start_char="4377" end_char="4382">origin</TOKEN>
<TOKEN id="token-40-32" pos="punct" morph="none" start_char="4383" end_char="4383">.</TOKEN>
</SEG>
<SEG id="segment-41" start_char="4385" end_char="4526">
<ORIGINAL_TEXT>The first known patient became ill on 1 December 2019 and had no links to the market, according to a paper published by Chinese researchers in</ORIGINAL_TEXT>
<TOKEN id="token-41-0" pos="word" morph="none" start_char="4385" end_char="4387">The</TOKEN>
<TOKEN id="token-41-1" pos="word" morph="none" start_char="4389" end_char="4393">first</TOKEN>
<TOKEN id="token-41-2" pos="word" morph="none" start_char="4395" end_char="4399">known</TOKEN>
<TOKEN id="token-41-3" pos="word" morph="none" start_char="4401" end_char="4407">patient</TOKEN>
<TOKEN id="token-41-4" pos="word" morph="none" start_char="4409" end_char="4414">became</TOKEN>
<TOKEN id="token-41-5" pos="word" morph="none" start_char="4416" end_char="4418">ill</TOKEN>
<TOKEN id="token-41-6" pos="word" morph="none" start_char="4420" end_char="4421">on</TOKEN>
<TOKEN id="token-41-7" pos="word" morph="none" start_char="4423" end_char="4423">1</TOKEN>
<TOKEN id="token-41-8" pos="word" morph="none" start_char="4425" end_char="4432">December</TOKEN>
<TOKEN id="token-41-9" pos="word" morph="none" start_char="4434" end_char="4437">2019</TOKEN>
<TOKEN id="token-41-10" pos="word" morph="none" start_char="4439" end_char="4441">and</TOKEN>
<TOKEN id="token-41-11" pos="word" morph="none" start_char="4443" end_char="4445">had</TOKEN>
<TOKEN id="token-41-12" pos="word" morph="none" start_char="4447" end_char="4448">no</TOKEN>
<TOKEN id="token-41-13" pos="word" morph="none" start_char="4450" end_char="4454">links</TOKEN>
<TOKEN id="token-41-14" pos="word" morph="none" start_char="4456" end_char="4457">to</TOKEN>
<TOKEN id="token-41-15" pos="word" morph="none" start_char="4459" end_char="4461">the</TOKEN>
<TOKEN id="token-41-16" pos="word" morph="none" start_char="4463" end_char="4468">market</TOKEN>
<TOKEN id="token-41-17" pos="punct" morph="none" start_char="4469" end_char="4469">,</TOKEN>
<TOKEN id="token-41-18" pos="word" morph="none" start_char="4471" end_char="4479">according</TOKEN>
<TOKEN id="token-41-19" pos="word" morph="none" start_char="4481" end_char="4482">to</TOKEN>
<TOKEN id="token-41-20" pos="word" morph="none" start_char="4484" end_char="4484">a</TOKEN>
<TOKEN id="token-41-21" pos="word" morph="none" start_char="4486" end_char="4490">paper</TOKEN>
<TOKEN id="token-41-22" pos="word" morph="none" start_char="4492" end_char="4500">published</TOKEN>
<TOKEN id="token-41-23" pos="word" morph="none" start_char="4502" end_char="4503">by</TOKEN>
<TOKEN id="token-41-24" pos="word" morph="none" start_char="4505" end_char="4511">Chinese</TOKEN>
<TOKEN id="token-41-25" pos="word" morph="none" start_char="4513" end_char="4523">researchers</TOKEN>
<TOKEN id="token-41-26" pos="word" morph="none" start_char="4525" end_char="4526">in</TOKEN>
</SEG>
<SEG id="segment-42" start_char="4529" end_char="4538">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-42-0" pos="word" morph="none" start_char="4529" end_char="4531">The</TOKEN>
<TOKEN id="token-42-1" pos="word" morph="none" start_char="4533" end_char="4538">Lancet</TOKEN>
</SEG>
<SEG id="segment-43" start_char="4541" end_char="4612">
<ORIGINAL_TEXT>on 24 January that offered details about the first 41 patients in Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-43-0" pos="word" morph="none" start_char="4541" end_char="4542">on</TOKEN>
<TOKEN id="token-43-1" pos="word" morph="none" start_char="4544" end_char="4545">24</TOKEN>
<TOKEN id="token-43-2" pos="word" morph="none" start_char="4547" end_char="4553">January</TOKEN>
<TOKEN id="token-43-3" pos="word" morph="none" start_char="4555" end_char="4558">that</TOKEN>
<TOKEN id="token-43-4" pos="word" morph="none" start_char="4560" end_char="4566">offered</TOKEN>
<TOKEN id="token-43-5" pos="word" morph="none" start_char="4568" end_char="4574">details</TOKEN>
<TOKEN id="token-43-6" pos="word" morph="none" start_char="4576" end_char="4580">about</TOKEN>
<TOKEN id="token-43-7" pos="word" morph="none" start_char="4582" end_char="4584">the</TOKEN>
<TOKEN id="token-43-8" pos="word" morph="none" start_char="4586" end_char="4590">first</TOKEN>
<TOKEN id="token-43-9" pos="word" morph="none" start_char="4592" end_char="4593">41</TOKEN>
<TOKEN id="token-43-10" pos="word" morph="none" start_char="4595" end_char="4602">patients</TOKEN>
<TOKEN id="token-43-11" pos="word" morph="none" start_char="4604" end_char="4605">in</TOKEN>
<TOKEN id="token-43-12" pos="word" morph="none" start_char="4607" end_char="4611">Wuhan</TOKEN>
<TOKEN id="token-43-13" pos="punct" morph="none" start_char="4612" end_char="4612">.</TOKEN>
</SEG>
<SEG id="segment-44" start_char="4614" end_char="4670">
<ORIGINAL_TEXT>In that group, 12 others also had no links to the market.</ORIGINAL_TEXT>
<TOKEN id="token-44-0" pos="word" morph="none" start_char="4614" end_char="4615">In</TOKEN>
<TOKEN id="token-44-1" pos="word" morph="none" start_char="4617" end_char="4620">that</TOKEN>
<TOKEN id="token-44-2" pos="word" morph="none" start_char="4622" end_char="4626">group</TOKEN>
<TOKEN id="token-44-3" pos="punct" morph="none" start_char="4627" end_char="4627">,</TOKEN>
<TOKEN id="token-44-4" pos="word" morph="none" start_char="4629" end_char="4630">12</TOKEN>
<TOKEN id="token-44-5" pos="word" morph="none" start_char="4632" end_char="4637">others</TOKEN>
<TOKEN id="token-44-6" pos="word" morph="none" start_char="4639" end_char="4642">also</TOKEN>
<TOKEN id="token-44-7" pos="word" morph="none" start_char="4644" end_char="4646">had</TOKEN>
<TOKEN id="token-44-8" pos="word" morph="none" start_char="4648" end_char="4649">no</TOKEN>
<TOKEN id="token-44-9" pos="word" morph="none" start_char="4651" end_char="4655">links</TOKEN>
<TOKEN id="token-44-10" pos="word" morph="none" start_char="4657" end_char="4658">to</TOKEN>
<TOKEN id="token-44-11" pos="word" morph="none" start_char="4660" end_char="4662">the</TOKEN>
<TOKEN id="token-44-12" pos="word" morph="none" start_char="4664" end_char="4669">market</TOKEN>
<TOKEN id="token-44-13" pos="punct" morph="none" start_char="4670" end_char="4670">.</TOKEN>
</SEG>
<SEG id="segment-45" start_char="4672" end_char="4831">
<ORIGINAL_TEXT>Lucey contends the virus was already circulating silently among humans before it contaminated the seafood market, possibly by infected animals, humans, or both.</ORIGINAL_TEXT>
<TOKEN id="token-45-0" pos="word" morph="none" start_char="4672" end_char="4676">Lucey</TOKEN>
<TOKEN id="token-45-1" pos="word" morph="none" start_char="4678" end_char="4685">contends</TOKEN>
<TOKEN id="token-45-2" pos="word" morph="none" start_char="4687" end_char="4689">the</TOKEN>
<TOKEN id="token-45-3" pos="word" morph="none" start_char="4691" end_char="4695">virus</TOKEN>
<TOKEN id="token-45-4" pos="word" morph="none" start_char="4697" end_char="4699">was</TOKEN>
<TOKEN id="token-45-5" pos="word" morph="none" start_char="4701" end_char="4707">already</TOKEN>
<TOKEN id="token-45-6" pos="word" morph="none" start_char="4709" end_char="4719">circulating</TOKEN>
<TOKEN id="token-45-7" pos="word" morph="none" start_char="4721" end_char="4728">silently</TOKEN>
<TOKEN id="token-45-8" pos="word" morph="none" start_char="4730" end_char="4734">among</TOKEN>
<TOKEN id="token-45-9" pos="word" morph="none" start_char="4736" end_char="4741">humans</TOKEN>
<TOKEN id="token-45-10" pos="word" morph="none" start_char="4743" end_char="4748">before</TOKEN>
<TOKEN id="token-45-11" pos="word" morph="none" start_char="4750" end_char="4751">it</TOKEN>
<TOKEN id="token-45-12" pos="word" morph="none" start_char="4753" end_char="4764">contaminated</TOKEN>
<TOKEN id="token-45-13" pos="word" morph="none" start_char="4766" end_char="4768">the</TOKEN>
<TOKEN id="token-45-14" pos="word" morph="none" start_char="4770" end_char="4776">seafood</TOKEN>
<TOKEN id="token-45-15" pos="word" morph="none" start_char="4778" end_char="4783">market</TOKEN>
<TOKEN id="token-45-16" pos="punct" morph="none" start_char="4784" end_char="4784">,</TOKEN>
<TOKEN id="token-45-17" pos="word" morph="none" start_char="4786" end_char="4793">possibly</TOKEN>
<TOKEN id="token-45-18" pos="word" morph="none" start_char="4795" end_char="4796">by</TOKEN>
<TOKEN id="token-45-19" pos="word" morph="none" start_char="4798" end_char="4805">infected</TOKEN>
<TOKEN id="token-45-20" pos="word" morph="none" start_char="4807" end_char="4813">animals</TOKEN>
<TOKEN id="token-45-21" pos="punct" morph="none" start_char="4814" end_char="4814">,</TOKEN>
<TOKEN id="token-45-22" pos="word" morph="none" start_char="4816" end_char="4821">humans</TOKEN>
<TOKEN id="token-45-23" pos="punct" morph="none" start_char="4822" end_char="4822">,</TOKEN>
<TOKEN id="token-45-24" pos="word" morph="none" start_char="4824" end_char="4825">or</TOKEN>
<TOKEN id="token-45-25" pos="word" morph="none" start_char="4827" end_char="4830">both</TOKEN>
<TOKEN id="token-45-26" pos="punct" morph="none" start_char="4831" end_char="4831">.</TOKEN>
</SEG>
<SEG id="segment-46" start_char="4834" end_char="4965">
<ORIGINAL_TEXT>The genomic data cannot pinpoint the origin, but they do show that the jump from animals to humans happened recently, Koopmans says.</ORIGINAL_TEXT>
<TOKEN id="token-46-0" pos="word" morph="none" start_char="4834" end_char="4836">The</TOKEN>
<TOKEN id="token-46-1" pos="word" morph="none" start_char="4838" end_char="4844">genomic</TOKEN>
<TOKEN id="token-46-2" pos="word" morph="none" start_char="4846" end_char="4849">data</TOKEN>
<TOKEN id="token-46-3" pos="word" morph="none" start_char="4851" end_char="4856">cannot</TOKEN>
<TOKEN id="token-46-4" pos="word" morph="none" start_char="4858" end_char="4865">pinpoint</TOKEN>
<TOKEN id="token-46-5" pos="word" morph="none" start_char="4867" end_char="4869">the</TOKEN>
<TOKEN id="token-46-6" pos="word" morph="none" start_char="4871" end_char="4876">origin</TOKEN>
<TOKEN id="token-46-7" pos="punct" morph="none" start_char="4877" end_char="4877">,</TOKEN>
<TOKEN id="token-46-8" pos="word" morph="none" start_char="4879" end_char="4881">but</TOKEN>
<TOKEN id="token-46-9" pos="word" morph="none" start_char="4883" end_char="4886">they</TOKEN>
<TOKEN id="token-46-10" pos="word" morph="none" start_char="4888" end_char="4889">do</TOKEN>
<TOKEN id="token-46-11" pos="word" morph="none" start_char="4891" end_char="4894">show</TOKEN>
<TOKEN id="token-46-12" pos="word" morph="none" start_char="4896" end_char="4899">that</TOKEN>
<TOKEN id="token-46-13" pos="word" morph="none" start_char="4901" end_char="4903">the</TOKEN>
<TOKEN id="token-46-14" pos="word" morph="none" start_char="4905" end_char="4908">jump</TOKEN>
<TOKEN id="token-46-15" pos="word" morph="none" start_char="4910" end_char="4913">from</TOKEN>
<TOKEN id="token-46-16" pos="word" morph="none" start_char="4915" end_char="4921">animals</TOKEN>
<TOKEN id="token-46-17" pos="word" morph="none" start_char="4923" end_char="4924">to</TOKEN>
<TOKEN id="token-46-18" pos="word" morph="none" start_char="4926" end_char="4931">humans</TOKEN>
<TOKEN id="token-46-19" pos="word" morph="none" start_char="4933" end_char="4940">happened</TOKEN>
<TOKEN id="token-46-20" pos="word" morph="none" start_char="4942" end_char="4949">recently</TOKEN>
<TOKEN id="token-46-21" pos="punct" morph="none" start_char="4950" end_char="4950">,</TOKEN>
<TOKEN id="token-46-22" pos="word" morph="none" start_char="4952" end_char="4959">Koopmans</TOKEN>
<TOKEN id="token-46-23" pos="word" morph="none" start_char="4961" end_char="4964">says</TOKEN>
<TOKEN id="token-46-24" pos="punct" morph="none" start_char="4965" end_char="4965">.</TOKEN>
</SEG>
<SEG id="segment-47" start_char="4967" end_char="5109">
<ORIGINAL_TEXT>An analysis of the first 30 publicly posted sequences shows they differ from each other by no more than seven nucleotides (see graphic, right).</ORIGINAL_TEXT>
<TOKEN id="token-47-0" pos="word" morph="none" start_char="4967" end_char="4968">An</TOKEN>
<TOKEN id="token-47-1" pos="word" morph="none" start_char="4970" end_char="4977">analysis</TOKEN>
<TOKEN id="token-47-2" pos="word" morph="none" start_char="4979" end_char="4980">of</TOKEN>
<TOKEN id="token-47-3" pos="word" morph="none" start_char="4982" end_char="4984">the</TOKEN>
<TOKEN id="token-47-4" pos="word" morph="none" start_char="4986" end_char="4990">first</TOKEN>
<TOKEN id="token-47-5" pos="word" morph="none" start_char="4992" end_char="4993">30</TOKEN>
<TOKEN id="token-47-6" pos="word" morph="none" start_char="4995" end_char="5002">publicly</TOKEN>
<TOKEN id="token-47-7" pos="word" morph="none" start_char="5004" end_char="5009">posted</TOKEN>
<TOKEN id="token-47-8" pos="word" morph="none" start_char="5011" end_char="5019">sequences</TOKEN>
<TOKEN id="token-47-9" pos="word" morph="none" start_char="5021" end_char="5025">shows</TOKEN>
<TOKEN id="token-47-10" pos="word" morph="none" start_char="5027" end_char="5030">they</TOKEN>
<TOKEN id="token-47-11" pos="word" morph="none" start_char="5032" end_char="5037">differ</TOKEN>
<TOKEN id="token-47-12" pos="word" morph="none" start_char="5039" end_char="5042">from</TOKEN>
<TOKEN id="token-47-13" pos="word" morph="none" start_char="5044" end_char="5047">each</TOKEN>
<TOKEN id="token-47-14" pos="word" morph="none" start_char="5049" end_char="5053">other</TOKEN>
<TOKEN id="token-47-15" pos="word" morph="none" start_char="5055" end_char="5056">by</TOKEN>
<TOKEN id="token-47-16" pos="word" morph="none" start_char="5058" end_char="5059">no</TOKEN>
<TOKEN id="token-47-17" pos="word" morph="none" start_char="5061" end_char="5064">more</TOKEN>
<TOKEN id="token-47-18" pos="word" morph="none" start_char="5066" end_char="5069">than</TOKEN>
<TOKEN id="token-47-19" pos="word" morph="none" start_char="5071" end_char="5075">seven</TOKEN>
<TOKEN id="token-47-20" pos="word" morph="none" start_char="5077" end_char="5087">nucleotides</TOKEN>
<TOKEN id="token-47-21" pos="punct" morph="none" start_char="5089" end_char="5089">(</TOKEN>
<TOKEN id="token-47-22" pos="word" morph="none" start_char="5090" end_char="5092">see</TOKEN>
<TOKEN id="token-47-23" pos="word" morph="none" start_char="5094" end_char="5100">graphic</TOKEN>
<TOKEN id="token-47-24" pos="punct" morph="none" start_char="5101" end_char="5101">,</TOKEN>
<TOKEN id="token-47-25" pos="word" morph="none" start_char="5103" end_char="5107">right</TOKEN>
<TOKEN id="token-47-26" pos="punct" morph="none" start_char="5108" end_char="5109">).</TOKEN>
</SEG>
<SEG id="segment-48" start_char="5111" end_char="5351">
<ORIGINAL_TEXT>Using these differences and presumed mutation rates, several groups have calculated that the virus began to spread around mid-November 2019—which supports the thesis that spread may have occurred before any of the cases linked to the market.</ORIGINAL_TEXT>
<TOKEN id="token-48-0" pos="word" morph="none" start_char="5111" end_char="5115">Using</TOKEN>
<TOKEN id="token-48-1" pos="word" morph="none" start_char="5117" end_char="5121">these</TOKEN>
<TOKEN id="token-48-2" pos="word" morph="none" start_char="5123" end_char="5133">differences</TOKEN>
<TOKEN id="token-48-3" pos="word" morph="none" start_char="5135" end_char="5137">and</TOKEN>
<TOKEN id="token-48-4" pos="word" morph="none" start_char="5139" end_char="5146">presumed</TOKEN>
<TOKEN id="token-48-5" pos="word" morph="none" start_char="5148" end_char="5155">mutation</TOKEN>
<TOKEN id="token-48-6" pos="word" morph="none" start_char="5157" end_char="5161">rates</TOKEN>
<TOKEN id="token-48-7" pos="punct" morph="none" start_char="5162" end_char="5162">,</TOKEN>
<TOKEN id="token-48-8" pos="word" morph="none" start_char="5164" end_char="5170">several</TOKEN>
<TOKEN id="token-48-9" pos="word" morph="none" start_char="5172" end_char="5177">groups</TOKEN>
<TOKEN id="token-48-10" pos="word" morph="none" start_char="5179" end_char="5182">have</TOKEN>
<TOKEN id="token-48-11" pos="word" morph="none" start_char="5184" end_char="5193">calculated</TOKEN>
<TOKEN id="token-48-12" pos="word" morph="none" start_char="5195" end_char="5198">that</TOKEN>
<TOKEN id="token-48-13" pos="word" morph="none" start_char="5200" end_char="5202">the</TOKEN>
<TOKEN id="token-48-14" pos="word" morph="none" start_char="5204" end_char="5208">virus</TOKEN>
<TOKEN id="token-48-15" pos="word" morph="none" start_char="5210" end_char="5214">began</TOKEN>
<TOKEN id="token-48-16" pos="word" morph="none" start_char="5216" end_char="5217">to</TOKEN>
<TOKEN id="token-48-17" pos="word" morph="none" start_char="5219" end_char="5224">spread</TOKEN>
<TOKEN id="token-48-18" pos="word" morph="none" start_char="5226" end_char="5231">around</TOKEN>
<TOKEN id="token-48-19" pos="unknown" morph="none" start_char="5233" end_char="5244">mid-November</TOKEN>
<TOKEN id="token-48-20" pos="unknown" morph="none" start_char="5246" end_char="5255">2019—which</TOKEN>
<TOKEN id="token-48-21" pos="word" morph="none" start_char="5257" end_char="5264">supports</TOKEN>
<TOKEN id="token-48-22" pos="word" morph="none" start_char="5266" end_char="5268">the</TOKEN>
<TOKEN id="token-48-23" pos="word" morph="none" start_char="5270" end_char="5275">thesis</TOKEN>
<TOKEN id="token-48-24" pos="word" morph="none" start_char="5277" end_char="5280">that</TOKEN>
<TOKEN id="token-48-25" pos="word" morph="none" start_char="5282" end_char="5287">spread</TOKEN>
<TOKEN id="token-48-26" pos="word" morph="none" start_char="5289" end_char="5291">may</TOKEN>
<TOKEN id="token-48-27" pos="word" morph="none" start_char="5293" end_char="5296">have</TOKEN>
<TOKEN id="token-48-28" pos="word" morph="none" start_char="5298" end_char="5305">occurred</TOKEN>
<TOKEN id="token-48-29" pos="word" morph="none" start_char="5307" end_char="5312">before</TOKEN>
<TOKEN id="token-48-30" pos="word" morph="none" start_char="5314" end_char="5316">any</TOKEN>
<TOKEN id="token-48-31" pos="word" morph="none" start_char="5318" end_char="5319">of</TOKEN>
<TOKEN id="token-48-32" pos="word" morph="none" start_char="5321" end_char="5323">the</TOKEN>
<TOKEN id="token-48-33" pos="word" morph="none" start_char="5325" end_char="5329">cases</TOKEN>
<TOKEN id="token-48-34" pos="word" morph="none" start_char="5331" end_char="5336">linked</TOKEN>
<TOKEN id="token-48-35" pos="word" morph="none" start_char="5338" end_char="5339">to</TOKEN>
<TOKEN id="token-48-36" pos="word" morph="none" start_char="5341" end_char="5343">the</TOKEN>
<TOKEN id="token-48-37" pos="word" morph="none" start_char="5345" end_char="5350">market</TOKEN>
<TOKEN id="token-48-38" pos="punct" morph="none" start_char="5351" end_char="5351">.</TOKEN>
</SEG>
<SEG id="segment-49" start_char="5353" end_char="5423">
<ORIGINAL_TEXT>One group put the origin of the outbreak as early as 18 September 2019.</ORIGINAL_TEXT>
<TOKEN id="token-49-0" pos="word" morph="none" start_char="5353" end_char="5355">One</TOKEN>
<TOKEN id="token-49-1" pos="word" morph="none" start_char="5357" end_char="5361">group</TOKEN>
<TOKEN id="token-49-2" pos="word" morph="none" start_char="5363" end_char="5365">put</TOKEN>
<TOKEN id="token-49-3" pos="word" morph="none" start_char="5367" end_char="5369">the</TOKEN>
<TOKEN id="token-49-4" pos="word" morph="none" start_char="5371" end_char="5376">origin</TOKEN>
<TOKEN id="token-49-5" pos="word" morph="none" start_char="5378" end_char="5379">of</TOKEN>
<TOKEN id="token-49-6" pos="word" morph="none" start_char="5381" end_char="5383">the</TOKEN>
<TOKEN id="token-49-7" pos="word" morph="none" start_char="5385" end_char="5392">outbreak</TOKEN>
<TOKEN id="token-49-8" pos="word" morph="none" start_char="5394" end_char="5395">as</TOKEN>
<TOKEN id="token-49-9" pos="word" morph="none" start_char="5397" end_char="5401">early</TOKEN>
<TOKEN id="token-49-10" pos="word" morph="none" start_char="5403" end_char="5404">as</TOKEN>
<TOKEN id="token-49-11" pos="word" morph="none" start_char="5406" end_char="5407">18</TOKEN>
<TOKEN id="token-49-12" pos="word" morph="none" start_char="5409" end_char="5417">September</TOKEN>
<TOKEN id="token-49-13" pos="word" morph="none" start_char="5419" end_char="5422">2019</TOKEN>
<TOKEN id="token-49-14" pos="punct" morph="none" start_char="5423" end_char="5423">.</TOKEN>
</SEG>
<SEG id="segment-50" start_char="5426" end_char="5529">
<ORIGINAL_TEXT>Bin Cao, a pulmonary specialist at Capital Medical University in Beijing and the corresponding author of</ORIGINAL_TEXT>
<TOKEN id="token-50-0" pos="word" morph="none" start_char="5426" end_char="5428">Bin</TOKEN>
<TOKEN id="token-50-1" pos="word" morph="none" start_char="5430" end_char="5432">Cao</TOKEN>
<TOKEN id="token-50-2" pos="punct" morph="none" start_char="5433" end_char="5433">,</TOKEN>
<TOKEN id="token-50-3" pos="word" morph="none" start_char="5435" end_char="5435">a</TOKEN>
<TOKEN id="token-50-4" pos="word" morph="none" start_char="5437" end_char="5445">pulmonary</TOKEN>
<TOKEN id="token-50-5" pos="word" morph="none" start_char="5447" end_char="5456">specialist</TOKEN>
<TOKEN id="token-50-6" pos="word" morph="none" start_char="5458" end_char="5459">at</TOKEN>
<TOKEN id="token-50-7" pos="word" morph="none" start_char="5461" end_char="5467">Capital</TOKEN>
<TOKEN id="token-50-8" pos="word" morph="none" start_char="5469" end_char="5475">Medical</TOKEN>
<TOKEN id="token-50-9" pos="word" morph="none" start_char="5477" end_char="5486">University</TOKEN>
<TOKEN id="token-50-10" pos="word" morph="none" start_char="5488" end_char="5489">in</TOKEN>
<TOKEN id="token-50-11" pos="word" morph="none" start_char="5491" end_char="5497">Beijing</TOKEN>
<TOKEN id="token-50-12" pos="word" morph="none" start_char="5499" end_char="5501">and</TOKEN>
<TOKEN id="token-50-13" pos="word" morph="none" start_char="5503" end_char="5505">the</TOKEN>
<TOKEN id="token-50-14" pos="word" morph="none" start_char="5507" end_char="5519">corresponding</TOKEN>
<TOKEN id="token-50-15" pos="word" morph="none" start_char="5521" end_char="5526">author</TOKEN>
<TOKEN id="token-50-16" pos="word" morph="none" start_char="5528" end_char="5529">of</TOKEN>
</SEG>
<SEG id="segment-51" start_char="5532" end_char="5541">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN id="token-51-0" pos="word" morph="none" start_char="5532" end_char="5534">The</TOKEN>
<TOKEN id="token-51-1" pos="word" morph="none" start_char="5536" end_char="5541">Lancet</TOKEN>
</SEG>
<SEG id="segment-52" start_char="5544" end_char="5607">
<ORIGINAL_TEXT>article, agrees the story is more complicated than many thought.</ORIGINAL_TEXT>
<TOKEN id="token-52-0" pos="word" morph="none" start_char="5544" end_char="5550">article</TOKEN>
<TOKEN id="token-52-1" pos="punct" morph="none" start_char="5551" end_char="5551">,</TOKEN>
<TOKEN id="token-52-2" pos="word" morph="none" start_char="5553" end_char="5558">agrees</TOKEN>
<TOKEN id="token-52-3" pos="word" morph="none" start_char="5560" end_char="5562">the</TOKEN>
<TOKEN id="token-52-4" pos="word" morph="none" start_char="5564" end_char="5568">story</TOKEN>
<TOKEN id="token-52-5" pos="word" morph="none" start_char="5570" end_char="5571">is</TOKEN>
<TOKEN id="token-52-6" pos="word" morph="none" start_char="5573" end_char="5576">more</TOKEN>
<TOKEN id="token-52-7" pos="word" morph="none" start_char="5578" end_char="5588">complicated</TOKEN>
<TOKEN id="token-52-8" pos="word" morph="none" start_char="5590" end_char="5593">than</TOKEN>
<TOKEN id="token-52-9" pos="word" morph="none" start_char="5595" end_char="5598">many</TOKEN>
<TOKEN id="token-52-10" pos="word" morph="none" start_char="5600" end_char="5606">thought</TOKEN>
<TOKEN id="token-52-11" pos="punct" morph="none" start_char="5607" end_char="5607">.</TOKEN>
</SEG>
<SEG id="segment-53" start_char="5609" end_char="5715">
<ORIGINAL_TEXT>"Now it seems clear that [the] seafood market is not the only origin of the virus," he wrote in an email to</ORIGINAL_TEXT>
<TOKEN id="token-53-0" pos="punct" morph="none" start_char="5609" end_char="5609">"</TOKEN>
<TOKEN id="token-53-1" pos="word" morph="none" start_char="5610" end_char="5612">Now</TOKEN>
<TOKEN id="token-53-2" pos="word" morph="none" start_char="5614" end_char="5615">it</TOKEN>
<TOKEN id="token-53-3" pos="word" morph="none" start_char="5617" end_char="5621">seems</TOKEN>
<TOKEN id="token-53-4" pos="word" morph="none" start_char="5623" end_char="5627">clear</TOKEN>
<TOKEN id="token-53-5" pos="word" morph="none" start_char="5629" end_char="5632">that</TOKEN>
<TOKEN id="token-53-6" pos="punct" morph="none" start_char="5634" end_char="5634">[</TOKEN>
<TOKEN id="token-53-7" pos="word" morph="none" start_char="5635" end_char="5637">the</TOKEN>
<TOKEN id="token-53-8" pos="punct" morph="none" start_char="5638" end_char="5638">]</TOKEN>
<TOKEN id="token-53-9" pos="word" morph="none" start_char="5640" end_char="5646">seafood</TOKEN>
<TOKEN id="token-53-10" pos="word" morph="none" start_char="5648" end_char="5653">market</TOKEN>
<TOKEN id="token-53-11" pos="word" morph="none" start_char="5655" end_char="5656">is</TOKEN>
<TOKEN id="token-53-12" pos="word" morph="none" start_char="5658" end_char="5660">not</TOKEN>
<TOKEN id="token-53-13" pos="word" morph="none" start_char="5662" end_char="5664">the</TOKEN>
<TOKEN id="token-53-14" pos="word" morph="none" start_char="5666" end_char="5669">only</TOKEN>
<TOKEN id="token-53-15" pos="word" morph="none" start_char="5671" end_char="5676">origin</TOKEN>
<TOKEN id="token-53-16" pos="word" morph="none" start_char="5678" end_char="5679">of</TOKEN>
<TOKEN id="token-53-17" pos="word" morph="none" start_char="5681" end_char="5683">the</TOKEN>
<TOKEN id="token-53-18" pos="word" morph="none" start_char="5685" end_char="5689">virus</TOKEN>
<TOKEN id="token-53-19" pos="punct" morph="none" start_char="5690" end_char="5691">,"</TOKEN>
<TOKEN id="token-53-20" pos="word" morph="none" start_char="5693" end_char="5694">he</TOKEN>
<TOKEN id="token-53-21" pos="word" morph="none" start_char="5696" end_char="5700">wrote</TOKEN>
<TOKEN id="token-53-22" pos="word" morph="none" start_char="5702" end_char="5703">in</TOKEN>
<TOKEN id="token-53-23" pos="word" morph="none" start_char="5705" end_char="5706">an</TOKEN>
<TOKEN id="token-53-24" pos="word" morph="none" start_char="5708" end_char="5712">email</TOKEN>
<TOKEN id="token-53-25" pos="word" morph="none" start_char="5714" end_char="5715">to</TOKEN>
</SEG>
<SEG id="segment-54" start_char="5718" end_char="5725">
<ORIGINAL_TEXT>Science.</ORIGINAL_TEXT>
<TOKEN id="token-54-0" pos="word" morph="none" start_char="5718" end_char="5724">Science</TOKEN>
<TOKEN id="token-54-1" pos="punct" morph="none" start_char="5725" end_char="5725">.</TOKEN>
</SEG>
<SEG id="segment-55" start_char="5728" end_char="5798">
<ORIGINAL_TEXT>"But to be honest, we still do not know where the virus came from now."</ORIGINAL_TEXT>
<TOKEN id="token-55-0" pos="punct" morph="none" start_char="5728" end_char="5728">"</TOKEN>
<TOKEN id="token-55-1" pos="word" morph="none" start_char="5729" end_char="5731">But</TOKEN>
<TOKEN id="token-55-2" pos="word" morph="none" start_char="5733" end_char="5734">to</TOKEN>
<TOKEN id="token-55-3" pos="word" morph="none" start_char="5736" end_char="5737">be</TOKEN>
<TOKEN id="token-55-4" pos="word" morph="none" start_char="5739" end_char="5744">honest</TOKEN>
<TOKEN id="token-55-5" pos="punct" morph="none" start_char="5745" end_char="5745">,</TOKEN>
<TOKEN id="token-55-6" pos="word" morph="none" start_char="5747" end_char="5748">we</TOKEN>
<TOKEN id="token-55-7" pos="word" morph="none" start_char="5750" end_char="5754">still</TOKEN>
<TOKEN id="token-55-8" pos="word" morph="none" start_char="5756" end_char="5757">do</TOKEN>
<TOKEN id="token-55-9" pos="word" morph="none" start_char="5759" end_char="5761">not</TOKEN>
<TOKEN id="token-55-10" pos="word" morph="none" start_char="5763" end_char="5766">know</TOKEN>
<TOKEN id="token-55-11" pos="word" morph="none" start_char="5768" end_char="5772">where</TOKEN>
<TOKEN id="token-55-12" pos="word" morph="none" start_char="5774" end_char="5776">the</TOKEN>
<TOKEN id="token-55-13" pos="word" morph="none" start_char="5778" end_char="5782">virus</TOKEN>
<TOKEN id="token-55-14" pos="word" morph="none" start_char="5784" end_char="5787">came</TOKEN>
<TOKEN id="token-55-15" pos="word" morph="none" start_char="5789" end_char="5792">from</TOKEN>
<TOKEN id="token-55-16" pos="word" morph="none" start_char="5794" end_char="5796">now</TOKEN>
<TOKEN id="token-55-17" pos="punct" morph="none" start_char="5797" end_char="5798">."</TOKEN>
</SEG>
<SEG id="segment-56" start_char="5801" end_char="5826">
<ORIGINAL_TEXT>Could Existing Drugs Work?</ORIGINAL_TEXT>
<TOKEN id="token-56-0" pos="word" morph="none" start_char="5801" end_char="5805">Could</TOKEN>
<TOKEN id="token-56-1" pos="word" morph="none" start_char="5807" end_char="5814">Existing</TOKEN>
<TOKEN id="token-56-2" pos="word" morph="none" start_char="5816" end_char="5820">Drugs</TOKEN>
<TOKEN id="token-56-3" pos="word" morph="none" start_char="5822" end_char="5825">Work</TOKEN>
<TOKEN id="token-56-4" pos="punct" morph="none" start_char="5826" end_char="5826">?</TOKEN>
</SEG>
<SEG id="segment-57" start_char="5830" end_char="5951">
<ORIGINAL_TEXT>It may take years to develop treatments specifically designed for 2019-nCoV, but researchers hope existing drugs can help.</ORIGINAL_TEXT>
<TOKEN id="token-57-0" pos="word" morph="none" start_char="5830" end_char="5831">It</TOKEN>
<TOKEN id="token-57-1" pos="word" morph="none" start_char="5833" end_char="5835">may</TOKEN>
<TOKEN id="token-57-2" pos="word" morph="none" start_char="5837" end_char="5840">take</TOKEN>
<TOKEN id="token-57-3" pos="word" morph="none" start_char="5842" end_char="5846">years</TOKEN>
<TOKEN id="token-57-4" pos="word" morph="none" start_char="5848" end_char="5849">to</TOKEN>
<TOKEN id="token-57-5" pos="word" morph="none" start_char="5851" end_char="5857">develop</TOKEN>
<TOKEN id="token-57-6" pos="word" morph="none" start_char="5859" end_char="5868">treatments</TOKEN>
<TOKEN id="token-57-7" pos="word" morph="none" start_char="5870" end_char="5881">specifically</TOKEN>
<TOKEN id="token-57-8" pos="word" morph="none" start_char="5883" end_char="5890">designed</TOKEN>
<TOKEN id="token-57-9" pos="word" morph="none" start_char="5892" end_char="5894">for</TOKEN>
<TOKEN id="token-57-10" pos="unknown" morph="none" start_char="5896" end_char="5904">2019-nCoV</TOKEN>
<TOKEN id="token-57-11" pos="punct" morph="none" start_char="5905" end_char="5905">,</TOKEN>
<TOKEN id="token-57-12" pos="word" morph="none" start_char="5907" end_char="5909">but</TOKEN>
<TOKEN id="token-57-13" pos="word" morph="none" start_char="5911" end_char="5921">researchers</TOKEN>
<TOKEN id="token-57-14" pos="word" morph="none" start_char="5923" end_char="5926">hope</TOKEN>
<TOKEN id="token-57-15" pos="word" morph="none" start_char="5928" end_char="5935">existing</TOKEN>
<TOKEN id="token-57-16" pos="word" morph="none" start_char="5937" end_char="5941">drugs</TOKEN>
<TOKEN id="token-57-17" pos="word" morph="none" start_char="5943" end_char="5945">can</TOKEN>
<TOKEN id="token-57-18" pos="word" morph="none" start_char="5947" end_char="5950">help</TOKEN>
<TOKEN id="token-57-19" pos="punct" morph="none" start_char="5951" end_char="5951">.</TOKEN>
</SEG>
<SEG id="segment-58" start_char="5953" end_char="6119">
<ORIGINAL_TEXT>Wuhan's Jin Yintan Hospital has already launched a randomized, controlled trial of the anti-HIV drug combination of lopinavir and ritonavir, according to the report in</ORIGINAL_TEXT>
<TOKEN id="token-58-0" pos="word" morph="none" start_char="5953" end_char="5959">Wuhan's</TOKEN>
<TOKEN id="token-58-1" pos="word" morph="none" start_char="5961" end_char="5963">Jin</TOKEN>
<TOKEN id="token-58-2" pos="word" morph="none" start_char="5965" end_char="5970">Yintan</TOKEN>
<TOKEN id="token-58-3" pos="word" morph="none" start_char="5972" end_char="5979">Hospital</TOKEN>
<TOKEN id="token-58-4" pos="word" morph="none" start_char="5981" end_char="5983">has</TOKEN>
<TOKEN id="token-58-5" pos="word" morph="none" start_char="5985" end_char="5991">already</TOKEN>
<TOKEN id="token-58-6" pos="word" morph="none" start_char="5993" end_char="6000">launched</TOKEN>
<TOKEN id="token-58-7" pos="word" morph="none" start_char="6002" end_char="6002">a</TOKEN>
<TOKEN id="token-58-8" pos="word" morph="none" start_char="6004" end_char="6013">randomized</TOKEN>
<TOKEN id="token-58-9" pos="punct" morph="none" start_char="6014" end_char="6014">,</TOKEN>
<TOKEN id="token-58-10" pos="word" morph="none" start_char="6016" end_char="6025">controlled</TOKEN>
<TOKEN id="token-58-11" pos="word" morph="none" start_char="6027" end_char="6031">trial</TOKEN>
<TOKEN id="token-58-12" pos="word" morph="none" start_char="6033" end_char="6034">of</TOKEN>
<TOKEN id="token-58-13" pos="word" morph="none" start_char="6036" end_char="6038">the</TOKEN>
<TOKEN id="token-58-14" pos="unknown" morph="none" start_char="6040" end_char="6047">anti-HIV</TOKEN>
<TOKEN id="token-58-15" pos="word" morph="none" start_char="6049" end_char="6052">drug</TOKEN>
<TOKEN id="token-58-16" pos="word" morph="none" start_char="6054" end_char="6064">combination</TOKEN>
<TOKEN id="token-58-17" pos="word" morph="none" start_char="6066" end_char="6067">of</TOKEN>
<TOKEN id="token-58-18" pos="word" morph="none" start_char="6069" end_char="6077">lopinavir</TOKEN>
<TOKEN id="token-58-19" pos="word" morph="none" start_char="6079" end_char="6081">and</TOKEN>
<TOKEN id="token-58-20" pos="word" morph="none" start_char="6083" end_char="6091">ritonavir</TOKEN>
<TOKEN id="token-58-21" pos="punct" morph="none" start_char="6092" end_char="6092">,</TOKEN>
<TOKEN id="token-58-22" pos="word" morph="none" start_char="6094" end_char="6102">according</TOKEN>
<TOKEN id="token-58-23" pos="word" morph="none" start_char="6104" end_char="6105">to</TOKEN>
<TOKEN id="token-58-24" pos="word" morph="none" start_char="6107" end_char="6109">the</TOKEN>
<TOKEN id="token-58-25" pos="word" morph="none" start_char="6111" end_char="6116">report</TOKEN>
<TOKEN id="token-58-26" pos="word" morph="none" start_char="6118" end_char="6119">in</TOKEN>
</SEG>
<SEG id="segment-59" start_char="6122" end_char="6132">
<ORIGINAL_TEXT>The Lancet.</ORIGINAL_TEXT>
<TOKEN id="token-59-0" pos="word" morph="none" start_char="6122" end_char="6124">The</TOKEN>
<TOKEN id="token-59-1" pos="word" morph="none" start_char="6126" end_char="6131">Lancet</TOKEN>
<TOKEN id="token-59-2" pos="punct" morph="none" start_char="6132" end_char="6132">.</TOKEN>
</SEG>
<SEG id="segment-60" start_char="6135" end_char="6253">
<ORIGINAL_TEXT>The duo targets the protease enzyme used by HIV to copy itself, and it might thwart the coronavirus's protease as well.</ORIGINAL_TEXT>
<TOKEN id="token-60-0" pos="word" morph="none" start_char="6135" end_char="6137">The</TOKEN>
<TOKEN id="token-60-1" pos="word" morph="none" start_char="6139" end_char="6141">duo</TOKEN>
<TOKEN id="token-60-2" pos="word" morph="none" start_char="6143" end_char="6149">targets</TOKEN>
<TOKEN id="token-60-3" pos="word" morph="none" start_char="6151" end_char="6153">the</TOKEN>
<TOKEN id="token-60-4" pos="word" morph="none" start_char="6155" end_char="6162">protease</TOKEN>
<TOKEN id="token-60-5" pos="word" morph="none" start_char="6164" end_char="6169">enzyme</TOKEN>
<TOKEN id="token-60-6" pos="word" morph="none" start_char="6171" end_char="6174">used</TOKEN>
<TOKEN id="token-60-7" pos="word" morph="none" start_char="6176" end_char="6177">by</TOKEN>
<TOKEN id="token-60-8" pos="word" morph="none" start_char="6179" end_char="6181">HIV</TOKEN>
<TOKEN id="token-60-9" pos="word" morph="none" start_char="6183" end_char="6184">to</TOKEN>
<TOKEN id="token-60-10" pos="word" morph="none" start_char="6186" end_char="6189">copy</TOKEN>
<TOKEN id="token-60-11" pos="word" morph="none" start_char="6191" end_char="6196">itself</TOKEN>
<TOKEN id="token-60-12" pos="punct" morph="none" start_char="6197" end_char="6197">,</TOKEN>
<TOKEN id="token-60-13" pos="word" morph="none" start_char="6199" end_char="6201">and</TOKEN>
<TOKEN id="token-60-14" pos="word" morph="none" start_char="6203" end_char="6204">it</TOKEN>
<TOKEN id="token-60-15" pos="word" morph="none" start_char="6206" end_char="6210">might</TOKEN>
<TOKEN id="token-60-16" pos="word" morph="none" start_char="6212" end_char="6217">thwart</TOKEN>
<TOKEN id="token-60-17" pos="word" morph="none" start_char="6219" end_char="6221">the</TOKEN>
<TOKEN id="token-60-18" pos="word" morph="none" start_char="6223" end_char="6235">coronavirus's</TOKEN>
<TOKEN id="token-60-19" pos="word" morph="none" start_char="6237" end_char="6244">protease</TOKEN>
<TOKEN id="token-60-20" pos="word" morph="none" start_char="6246" end_char="6247">as</TOKEN>
<TOKEN id="token-60-21" pos="word" morph="none" start_char="6249" end_char="6252">well</TOKEN>
<TOKEN id="token-60-22" pos="punct" morph="none" start_char="6253" end_char="6253">.</TOKEN>
</SEG>
<SEG id="segment-61" start_char="6255" end_char="6484">
<ORIGINAL_TEXT>There's a precedent from the SARS outbreak: In a nonrandomized trial published in 2004, researchers saw an "apparent improved outcome" from the same two protease inhibitors, combined with a third drug, ribavirin, in SARS patients.</ORIGINAL_TEXT>
<TOKEN id="token-61-0" pos="word" morph="none" start_char="6255" end_char="6261">There's</TOKEN>
<TOKEN id="token-61-1" pos="word" morph="none" start_char="6263" end_char="6263">a</TOKEN>
<TOKEN id="token-61-2" pos="word" morph="none" start_char="6265" end_char="6273">precedent</TOKEN>
<TOKEN id="token-61-3" pos="word" morph="none" start_char="6275" end_char="6278">from</TOKEN>
<TOKEN id="token-61-4" pos="word" morph="none" start_char="6280" end_char="6282">the</TOKEN>
<TOKEN id="token-61-5" pos="word" morph="none" start_char="6284" end_char="6287">SARS</TOKEN>
<TOKEN id="token-61-6" pos="word" morph="none" start_char="6289" end_char="6296">outbreak</TOKEN>
<TOKEN id="token-61-7" pos="punct" morph="none" start_char="6297" end_char="6297">:</TOKEN>
<TOKEN id="token-61-8" pos="word" morph="none" start_char="6299" end_char="6300">In</TOKEN>
<TOKEN id="token-61-9" pos="word" morph="none" start_char="6302" end_char="6302">a</TOKEN>
<TOKEN id="token-61-10" pos="word" morph="none" start_char="6304" end_char="6316">nonrandomized</TOKEN>
<TOKEN id="token-61-11" pos="word" morph="none" start_char="6318" end_char="6322">trial</TOKEN>
<TOKEN id="token-61-12" pos="word" morph="none" start_char="6324" end_char="6332">published</TOKEN>
<TOKEN id="token-61-13" pos="word" morph="none" start_char="6334" end_char="6335">in</TOKEN>
<TOKEN id="token-61-14" pos="word" morph="none" start_char="6337" end_char="6340">2004</TOKEN>
<TOKEN id="token-61-15" pos="punct" morph="none" start_char="6341" end_char="6341">,</TOKEN>
<TOKEN id="token-61-16" pos="word" morph="none" start_char="6343" end_char="6353">researchers</TOKEN>
<TOKEN id="token-61-17" pos="word" morph="none" start_char="6355" end_char="6357">saw</TOKEN>
<TOKEN id="token-61-18" pos="word" morph="none" start_char="6359" end_char="6360">an</TOKEN>
<TOKEN id="token-61-19" pos="punct" morph="none" start_char="6362" end_char="6362">"</TOKEN>
<TOKEN id="token-61-20" pos="word" morph="none" start_char="6363" end_char="6370">apparent</TOKEN>
<TOKEN id="token-61-21" pos="word" morph="none" start_char="6372" end_char="6379">improved</TOKEN>
<TOKEN id="token-61-22" pos="word" morph="none" start_char="6381" end_char="6387">outcome</TOKEN>
<TOKEN id="token-61-23" pos="punct" morph="none" start_char="6388" end_char="6388">"</TOKEN>
<TOKEN id="token-61-24" pos="word" morph="none" start_char="6390" end_char="6393">from</TOKEN>
<TOKEN id="token-61-25" pos="word" morph="none" start_char="6395" end_char="6397">the</TOKEN>
<TOKEN id="token-61-26" pos="word" morph="none" start_char="6399" end_char="6402">same</TOKEN>
<TOKEN id="token-61-27" pos="word" morph="none" start_char="6404" end_char="6406">two</TOKEN>
<TOKEN id="token-61-28" pos="word" morph="none" start_char="6408" end_char="6415">protease</TOKEN>
<TOKEN id="token-61-29" pos="word" morph="none" start_char="6417" end_char="6426">inhibitors</TOKEN>
<TOKEN id="token-61-30" pos="punct" morph="none" start_char="6427" end_char="6427">,</TOKEN>
<TOKEN id="token-61-31" pos="word" morph="none" start_char="6429" end_char="6436">combined</TOKEN>
<TOKEN id="token-61-32" pos="word" morph="none" start_char="6438" end_char="6441">with</TOKEN>
<TOKEN id="token-61-33" pos="word" morph="none" start_char="6443" end_char="6443">a</TOKEN>
<TOKEN id="token-61-34" pos="word" morph="none" start_char="6445" end_char="6449">third</TOKEN>
<TOKEN id="token-61-35" pos="word" morph="none" start_char="6451" end_char="6454">drug</TOKEN>
<TOKEN id="token-61-36" pos="punct" morph="none" start_char="6455" end_char="6455">,</TOKEN>
<TOKEN id="token-61-37" pos="word" morph="none" start_char="6457" end_char="6465">ribavirin</TOKEN>
<TOKEN id="token-61-38" pos="punct" morph="none" start_char="6466" end_char="6466">,</TOKEN>
<TOKEN id="token-61-39" pos="word" morph="none" start_char="6468" end_char="6469">in</TOKEN>
<TOKEN id="token-61-40" pos="word" morph="none" start_char="6471" end_char="6474">SARS</TOKEN>
<TOKEN id="token-61-41" pos="word" morph="none" start_char="6476" end_char="6483">patients</TOKEN>
<TOKEN id="token-61-42" pos="punct" morph="none" start_char="6484" end_char="6484">.</TOKEN>
</SEG>
<SEG id="segment-62" start_char="6487" end_char="6735">
<ORIGINAL_TEXT>Saudi Arabia is now conducting a trial with the same protease inhibitors, combined with interferon beta-1b, against Middle East respiratory syndrome (MERS), a coronavirus distantly related to SARS and 2019-nCoV that is occasionally spread by camels.</ORIGINAL_TEXT>
<TOKEN id="token-62-0" pos="word" morph="none" start_char="6487" end_char="6491">Saudi</TOKEN>
<TOKEN id="token-62-1" pos="word" morph="none" start_char="6493" end_char="6498">Arabia</TOKEN>
<TOKEN id="token-62-2" pos="word" morph="none" start_char="6500" end_char="6501">is</TOKEN>
<TOKEN id="token-62-3" pos="word" morph="none" start_char="6503" end_char="6505">now</TOKEN>
<TOKEN id="token-62-4" pos="word" morph="none" start_char="6507" end_char="6516">conducting</TOKEN>
<TOKEN id="token-62-5" pos="word" morph="none" start_char="6518" end_char="6518">a</TOKEN>
<TOKEN id="token-62-6" pos="word" morph="none" start_char="6520" end_char="6524">trial</TOKEN>
<TOKEN id="token-62-7" pos="word" morph="none" start_char="6526" end_char="6529">with</TOKEN>
<TOKEN id="token-62-8" pos="word" morph="none" start_char="6531" end_char="6533">the</TOKEN>
<TOKEN id="token-62-9" pos="word" morph="none" start_char="6535" end_char="6538">same</TOKEN>
<TOKEN id="token-62-10" pos="word" morph="none" start_char="6540" end_char="6547">protease</TOKEN>
<TOKEN id="token-62-11" pos="word" morph="none" start_char="6549" end_char="6558">inhibitors</TOKEN>
<TOKEN id="token-62-12" pos="punct" morph="none" start_char="6559" end_char="6559">,</TOKEN>
<TOKEN id="token-62-13" pos="word" morph="none" start_char="6561" end_char="6568">combined</TOKEN>
<TOKEN id="token-62-14" pos="word" morph="none" start_char="6570" end_char="6573">with</TOKEN>
<TOKEN id="token-62-15" pos="word" morph="none" start_char="6575" end_char="6584">interferon</TOKEN>
<TOKEN id="token-62-16" pos="unknown" morph="none" start_char="6586" end_char="6592">beta-1b</TOKEN>
<TOKEN id="token-62-17" pos="punct" morph="none" start_char="6593" end_char="6593">,</TOKEN>
<TOKEN id="token-62-18" pos="word" morph="none" start_char="6595" end_char="6601">against</TOKEN>
<TOKEN id="token-62-19" pos="word" morph="none" start_char="6603" end_char="6608">Middle</TOKEN>
<TOKEN id="token-62-20" pos="word" morph="none" start_char="6610" end_char="6613">East</TOKEN>
<TOKEN id="token-62-21" pos="word" morph="none" start_char="6615" end_char="6625">respiratory</TOKEN>
<TOKEN id="token-62-22" pos="word" morph="none" start_char="6627" end_char="6634">syndrome</TOKEN>
<TOKEN id="token-62-23" pos="punct" morph="none" start_char="6636" end_char="6636">(</TOKEN>
<TOKEN id="token-62-24" pos="word" morph="none" start_char="6637" end_char="6640">MERS</TOKEN>
<TOKEN id="token-62-25" pos="punct" morph="none" start_char="6641" end_char="6642">),</TOKEN>
<TOKEN id="token-62-26" pos="word" morph="none" start_char="6644" end_char="6644">a</TOKEN>
<TOKEN id="token-62-27" pos="word" morph="none" start_char="6646" end_char="6656">coronavirus</TOKEN>
<TOKEN id="token-62-28" pos="word" morph="none" start_char="6658" end_char="6666">distantly</TOKEN>
<TOKEN id="token-62-29" pos="word" morph="none" start_char="6668" end_char="6674">related</TOKEN>
<TOKEN id="token-62-30" pos="word" morph="none" start_char="6676" end_char="6677">to</TOKEN>
<TOKEN id="token-62-31" pos="word" morph="none" start_char="6679" end_char="6682">SARS</TOKEN>
<TOKEN id="token-62-32" pos="word" morph="none" start_char="6684" end_char="6686">and</TOKEN>
<TOKEN id="token-62-33" pos="unknown" morph="none" start_char="6688" end_char="6696">2019-nCoV</TOKEN>
<TOKEN id="token-62-34" pos="word" morph="none" start_char="6698" end_char="6701">that</TOKEN>
<TOKEN id="token-62-35" pos="word" morph="none" start_char="6703" end_char="6704">is</TOKEN>
<TOKEN id="token-62-36" pos="word" morph="none" start_char="6706" end_char="6717">occasionally</TOKEN>
<TOKEN id="token-62-37" pos="word" morph="none" start_char="6719" end_char="6724">spread</TOKEN>
<TOKEN id="token-62-38" pos="word" morph="none" start_char="6726" end_char="6727">by</TOKEN>
<TOKEN id="token-62-39" pos="word" morph="none" start_char="6729" end_char="6734">camels</TOKEN>
<TOKEN id="token-62-40" pos="punct" morph="none" start_char="6735" end_char="6735">.</TOKEN>
</SEG>
<SEG id="segment-63" start_char="6737" end_char="6879">
<ORIGINAL_TEXT>But in a recent mouse study by Ralph Baric of the University of North Carolina, Chapel Hill, this cocktail had lackluster results against MERS.</ORIGINAL_TEXT>
<TOKEN id="token-63-0" pos="word" morph="none" start_char="6737" end_char="6739">But</TOKEN>
<TOKEN id="token-63-1" pos="word" morph="none" start_char="6741" end_char="6742">in</TOKEN>
<TOKEN id="token-63-2" pos="word" morph="none" start_char="6744" end_char="6744">a</TOKEN>
<TOKEN id="token-63-3" pos="word" morph="none" start_char="6746" end_char="6751">recent</TOKEN>
<TOKEN id="token-63-4" pos="word" morph="none" start_char="6753" end_char="6757">mouse</TOKEN>
<TOKEN id="token-63-5" pos="word" morph="none" start_char="6759" end_char="6763">study</TOKEN>
<TOKEN id="token-63-6" pos="word" morph="none" start_char="6765" end_char="6766">by</TOKEN>
<TOKEN id="token-63-7" pos="word" morph="none" start_char="6768" end_char="6772">Ralph</TOKEN>
<TOKEN id="token-63-8" pos="word" morph="none" start_char="6774" end_char="6778">Baric</TOKEN>
<TOKEN id="token-63-9" pos="word" morph="none" start_char="6780" end_char="6781">of</TOKEN>
<TOKEN id="token-63-10" pos="word" morph="none" start_char="6783" end_char="6785">the</TOKEN>
<TOKEN id="token-63-11" pos="word" morph="none" start_char="6787" end_char="6796">University</TOKEN>
<TOKEN id="token-63-12" pos="word" morph="none" start_char="6798" end_char="6799">of</TOKEN>
<TOKEN id="token-63-13" pos="word" morph="none" start_char="6801" end_char="6805">North</TOKEN>
<TOKEN id="token-63-14" pos="word" morph="none" start_char="6807" end_char="6814">Carolina</TOKEN>
<TOKEN id="token-63-15" pos="punct" morph="none" start_char="6815" end_char="6815">,</TOKEN>
<TOKEN id="token-63-16" pos="word" morph="none" start_char="6817" end_char="6822">Chapel</TOKEN>
<TOKEN id="token-63-17" pos="word" morph="none" start_char="6824" end_char="6827">Hill</TOKEN>
<TOKEN id="token-63-18" pos="punct" morph="none" start_char="6828" end_char="6828">,</TOKEN>
<TOKEN id="token-63-19" pos="word" morph="none" start_char="6830" end_char="6833">this</TOKEN>
<TOKEN id="token-63-20" pos="word" morph="none" start_char="6835" end_char="6842">cocktail</TOKEN>
<TOKEN id="token-63-21" pos="word" morph="none" start_char="6844" end_char="6846">had</TOKEN>
<TOKEN id="token-63-22" pos="word" morph="none" start_char="6848" end_char="6857">lackluster</TOKEN>
<TOKEN id="token-63-23" pos="word" morph="none" start_char="6859" end_char="6865">results</TOKEN>
<TOKEN id="token-63-24" pos="word" morph="none" start_char="6867" end_char="6873">against</TOKEN>
<TOKEN id="token-63-25" pos="word" morph="none" start_char="6875" end_char="6878">MERS</TOKEN>
<TOKEN id="token-63-26" pos="punct" morph="none" start_char="6879" end_char="6879">.</TOKEN>
</SEG>
<SEG id="segment-64" start_char="6882" end_char="7056">
<ORIGINAL_TEXT>The same study showed better outcomes for remdesivir, an experimental drug made by Gilead and previously tested against Ebola that interferes with the viral polymerase enzyme.</ORIGINAL_TEXT>
<TOKEN id="token-64-0" pos="word" morph="none" start_char="6882" end_char="6884">The</TOKEN>
<TOKEN id="token-64-1" pos="word" morph="none" start_char="6886" end_char="6889">same</TOKEN>
<TOKEN id="token-64-2" pos="word" morph="none" start_char="6891" end_char="6895">study</TOKEN>
<TOKEN id="token-64-3" pos="word" morph="none" start_char="6897" end_char="6902">showed</TOKEN>
<TOKEN id="token-64-4" pos="word" morph="none" start_char="6904" end_char="6909">better</TOKEN>
<TOKEN id="token-64-5" pos="word" morph="none" start_char="6911" end_char="6918">outcomes</TOKEN>
<TOKEN id="token-64-6" pos="word" morph="none" start_char="6920" end_char="6922">for</TOKEN>
<TOKEN id="token-64-7" pos="word" morph="none" start_char="6924" end_char="6933">remdesivir</TOKEN>
<TOKEN id="token-64-8" pos="punct" morph="none" start_char="6934" end_char="6934">,</TOKEN>
<TOKEN id="token-64-9" pos="word" morph="none" start_char="6936" end_char="6937">an</TOKEN>
<TOKEN id="token-64-10" pos="word" morph="none" start_char="6939" end_char="6950">experimental</TOKEN>
<TOKEN id="token-64-11" pos="word" morph="none" start_char="6952" end_char="6955">drug</TOKEN>
<TOKEN id="token-64-12" pos="word" morph="none" start_char="6957" end_char="6960">made</TOKEN>
<TOKEN id="token-64-13" pos="word" morph="none" start_char="6962" end_char="6963">by</TOKEN>
<TOKEN id="token-64-14" pos="word" morph="none" start_char="6965" end_char="6970">Gilead</TOKEN>
<TOKEN id="token-64-15" pos="word" morph="none" start_char="6972" end_char="6974">and</TOKEN>
<TOKEN id="token-64-16" pos="word" morph="none" start_char="6976" end_char="6985">previously</TOKEN>
<TOKEN id="token-64-17" pos="word" morph="none" start_char="6987" end_char="6992">tested</TOKEN>
<TOKEN id="token-64-18" pos="word" morph="none" start_char="6994" end_char="7000">against</TOKEN>
<TOKEN id="token-64-19" pos="word" morph="none" start_char="7002" end_char="7006">Ebola</TOKEN>
<TOKEN id="token-64-20" pos="word" morph="none" start_char="7008" end_char="7011">that</TOKEN>
<TOKEN id="token-64-21" pos="word" morph="none" start_char="7013" end_char="7022">interferes</TOKEN>
<TOKEN id="token-64-22" pos="word" morph="none" start_char="7024" end_char="7027">with</TOKEN>
<TOKEN id="token-64-23" pos="word" morph="none" start_char="7029" end_char="7031">the</TOKEN>
<TOKEN id="token-64-24" pos="word" morph="none" start_char="7033" end_char="7037">viral</TOKEN>
<TOKEN id="token-64-25" pos="word" morph="none" start_char="7039" end_char="7048">polymerase</TOKEN>
<TOKEN id="token-64-26" pos="word" morph="none" start_char="7050" end_char="7055">enzyme</TOKEN>
<TOKEN id="token-64-27" pos="punct" morph="none" start_char="7056" end_char="7056">.</TOKEN>
</SEG>
<SEG id="segment-65" start_char="7058" end_char="7174">
<ORIGINAL_TEXT>Remdesivir combined with interferon slowed viral replication in MERS-infected mice, and their lung function improved.</ORIGINAL_TEXT>
<TOKEN id="token-65-0" pos="word" morph="none" start_char="7058" end_char="7067">Remdesivir</TOKEN>
<TOKEN id="token-65-1" pos="word" morph="none" start_char="7069" end_char="7076">combined</TOKEN>
<TOKEN id="token-65-2" pos="word" morph="none" start_char="7078" end_char="7081">with</TOKEN>
<TOKEN id="token-65-3" pos="word" morph="none" start_char="7083" end_char="7092">interferon</TOKEN>
<TOKEN id="token-65-4" pos="word" morph="none" start_char="7094" end_char="7099">slowed</TOKEN>
<TOKEN id="token-65-5" pos="word" morph="none" start_char="7101" end_char="7105">viral</TOKEN>
<TOKEN id="token-65-6" pos="word" morph="none" start_char="7107" end_char="7117">replication</TOKEN>
<TOKEN id="token-65-7" pos="word" morph="none" start_char="7119" end_char="7120">in</TOKEN>
<TOKEN id="token-65-8" pos="unknown" morph="none" start_char="7122" end_char="7134">MERS-infected</TOKEN>
<TOKEN id="token-65-9" pos="word" morph="none" start_char="7136" end_char="7139">mice</TOKEN>
<TOKEN id="token-65-10" pos="punct" morph="none" start_char="7140" end_char="7140">,</TOKEN>
<TOKEN id="token-65-11" pos="word" morph="none" start_char="7142" end_char="7144">and</TOKEN>
<TOKEN id="token-65-12" pos="word" morph="none" start_char="7146" end_char="7150">their</TOKEN>
<TOKEN id="token-65-13" pos="word" morph="none" start_char="7152" end_char="7155">lung</TOKEN>
<TOKEN id="token-65-14" pos="word" morph="none" start_char="7157" end_char="7164">function</TOKEN>
<TOKEN id="token-65-15" pos="word" morph="none" start_char="7166" end_char="7173">improved</TOKEN>
<TOKEN id="token-65-16" pos="punct" morph="none" start_char="7174" end_char="7174">.</TOKEN>
</SEG>
<SEG id="segment-66" start_char="7176" end_char="7379">
<ORIGINAL_TEXT>"Remdesivir has had activity against every coronavirus we've tested, and I'd be surprised if it didn't have activity against" 2019-nCoV, says co-author Mark Denison, a virologist at Vanderbilt University.</ORIGINAL_TEXT>
<TOKEN id="token-66-0" pos="punct" morph="none" start_char="7176" end_char="7176">"</TOKEN>
<TOKEN id="token-66-1" pos="word" morph="none" start_char="7177" end_char="7186">Remdesivir</TOKEN>
<TOKEN id="token-66-2" pos="word" morph="none" start_char="7188" end_char="7190">has</TOKEN>
<TOKEN id="token-66-3" pos="word" morph="none" start_char="7192" end_char="7194">had</TOKEN>
<TOKEN id="token-66-4" pos="word" morph="none" start_char="7196" end_char="7203">activity</TOKEN>
<TOKEN id="token-66-5" pos="word" morph="none" start_char="7205" end_char="7211">against</TOKEN>
<TOKEN id="token-66-6" pos="word" morph="none" start_char="7213" end_char="7217">every</TOKEN>
<TOKEN id="token-66-7" pos="word" morph="none" start_char="7219" end_char="7229">coronavirus</TOKEN>
<TOKEN id="token-66-8" pos="word" morph="none" start_char="7231" end_char="7235">we've</TOKEN>
<TOKEN id="token-66-9" pos="word" morph="none" start_char="7237" end_char="7242">tested</TOKEN>
<TOKEN id="token-66-10" pos="punct" morph="none" start_char="7243" end_char="7243">,</TOKEN>
<TOKEN id="token-66-11" pos="word" morph="none" start_char="7245" end_char="7247">and</TOKEN>
<TOKEN id="token-66-12" pos="word" morph="none" start_char="7249" end_char="7251">I'd</TOKEN>
<TOKEN id="token-66-13" pos="word" morph="none" start_char="7253" end_char="7254">be</TOKEN>
<TOKEN id="token-66-14" pos="word" morph="none" start_char="7256" end_char="7264">surprised</TOKEN>
<TOKEN id="token-66-15" pos="word" morph="none" start_char="7266" end_char="7267">if</TOKEN>
<TOKEN id="token-66-16" pos="word" morph="none" start_char="7269" end_char="7270">it</TOKEN>
<TOKEN id="token-66-17" pos="word" morph="none" start_char="7272" end_char="7277">didn't</TOKEN>
<TOKEN id="token-66-18" pos="word" morph="none" start_char="7279" end_char="7282">have</TOKEN>
<TOKEN id="token-66-19" pos="word" morph="none" start_char="7284" end_char="7291">activity</TOKEN>
<TOKEN id="token-66-20" pos="word" morph="none" start_char="7293" end_char="7299">against</TOKEN>
<TOKEN id="token-66-21" pos="punct" morph="none" start_char="7300" end_char="7300">"</TOKEN>
<TOKEN id="token-66-22" pos="unknown" morph="none" start_char="7302" end_char="7310">2019-nCoV</TOKEN>
<TOKEN id="token-66-23" pos="punct" morph="none" start_char="7311" end_char="7311">,</TOKEN>
<TOKEN id="token-66-24" pos="word" morph="none" start_char="7313" end_char="7316">says</TOKEN>
<TOKEN id="token-66-25" pos="unknown" morph="none" start_char="7318" end_char="7326">co-author</TOKEN>
<TOKEN id="token-66-26" pos="word" morph="none" start_char="7328" end_char="7331">Mark</TOKEN>
<TOKEN id="token-66-27" pos="word" morph="none" start_char="7333" end_char="7339">Denison</TOKEN>
<TOKEN id="token-66-28" pos="punct" morph="none" start_char="7340" end_char="7340">,</TOKEN>
<TOKEN id="token-66-29" pos="word" morph="none" start_char="7342" end_char="7342">a</TOKEN>
<TOKEN id="token-66-30" pos="word" morph="none" start_char="7344" end_char="7353">virologist</TOKEN>
<TOKEN id="token-66-31" pos="word" morph="none" start_char="7355" end_char="7356">at</TOKEN>
<TOKEN id="token-66-32" pos="word" morph="none" start_char="7358" end_char="7367">Vanderbilt</TOKEN>
<TOKEN id="token-66-33" pos="word" morph="none" start_char="7369" end_char="7378">University</TOKEN>
<TOKEN id="token-66-34" pos="punct" morph="none" start_char="7379" end_char="7379">.</TOKEN>
</SEG>
<SEG id="segment-67" start_char="7382" end_char="7440">
<ORIGINAL_TEXT>Development of entirely new treatments has started as well.</ORIGINAL_TEXT>
<TOKEN id="token-67-0" pos="word" morph="none" start_char="7382" end_char="7392">Development</TOKEN>
<TOKEN id="token-67-1" pos="word" morph="none" start_char="7394" end_char="7395">of</TOKEN>
<TOKEN id="token-67-2" pos="word" morph="none" start_char="7397" end_char="7404">entirely</TOKEN>
<TOKEN id="token-67-3" pos="word" morph="none" start_char="7406" end_char="7408">new</TOKEN>
<TOKEN id="token-67-4" pos="word" morph="none" start_char="7410" end_char="7419">treatments</TOKEN>
<TOKEN id="token-67-5" pos="word" morph="none" start_char="7421" end_char="7423">has</TOKEN>
<TOKEN id="token-67-6" pos="word" morph="none" start_char="7425" end_char="7431">started</TOKEN>
<TOKEN id="token-67-7" pos="word" morph="none" start_char="7433" end_char="7434">as</TOKEN>
<TOKEN id="token-67-8" pos="word" morph="none" start_char="7436" end_char="7439">well</TOKEN>
<TOKEN id="token-67-9" pos="punct" morph="none" start_char="7440" end_char="7440">.</TOKEN>
</SEG>
<SEG id="segment-68" start_char="7442" end_char="7577">
<ORIGINAL_TEXT>U.S. biotech Regeneron is trying to identify monoclonal antibodies effective against 2019-nCoV, as it did previously for MERS and Ebola.</ORIGINAL_TEXT>
<TOKEN id="token-68-0" pos="unknown" morph="none" start_char="7442" end_char="7444">U.S</TOKEN>
<TOKEN id="token-68-1" pos="punct" morph="none" start_char="7445" end_char="7445">.</TOKEN>
<TOKEN id="token-68-2" pos="word" morph="none" start_char="7447" end_char="7453">biotech</TOKEN>
<TOKEN id="token-68-3" pos="word" morph="none" start_char="7455" end_char="7463">Regeneron</TOKEN>
<TOKEN id="token-68-4" pos="word" morph="none" start_char="7465" end_char="7466">is</TOKEN>
<TOKEN id="token-68-5" pos="word" morph="none" start_char="7468" end_char="7473">trying</TOKEN>
<TOKEN id="token-68-6" pos="word" morph="none" start_char="7475" end_char="7476">to</TOKEN>
<TOKEN id="token-68-7" pos="word" morph="none" start_char="7478" end_char="7485">identify</TOKEN>
<TOKEN id="token-68-8" pos="word" morph="none" start_char="7487" end_char="7496">monoclonal</TOKEN>
<TOKEN id="token-68-9" pos="word" morph="none" start_char="7498" end_char="7507">antibodies</TOKEN>
<TOKEN id="token-68-10" pos="word" morph="none" start_char="7509" end_char="7517">effective</TOKEN>
<TOKEN id="token-68-11" pos="word" morph="none" start_char="7519" end_char="7525">against</TOKEN>
<TOKEN id="token-68-12" pos="unknown" morph="none" start_char="7527" end_char="7535">2019-nCoV</TOKEN>
<TOKEN id="token-68-13" pos="punct" morph="none" start_char="7536" end_char="7536">,</TOKEN>
<TOKEN id="token-68-14" pos="word" morph="none" start_char="7538" end_char="7539">as</TOKEN>
<TOKEN id="token-68-15" pos="word" morph="none" start_char="7541" end_char="7542">it</TOKEN>
<TOKEN id="token-68-16" pos="word" morph="none" start_char="7544" end_char="7546">did</TOKEN>
<TOKEN id="token-68-17" pos="word" morph="none" start_char="7548" end_char="7557">previously</TOKEN>
<TOKEN id="token-68-18" pos="word" morph="none" start_char="7559" end_char="7561">for</TOKEN>
<TOKEN id="token-68-19" pos="word" morph="none" start_char="7563" end_char="7566">MERS</TOKEN>
<TOKEN id="token-68-20" pos="word" morph="none" start_char="7568" end_char="7570">and</TOKEN>
<TOKEN id="token-68-21" pos="word" morph="none" start_char="7572" end_char="7576">Ebola</TOKEN>
<TOKEN id="token-68-22" pos="punct" morph="none" start_char="7577" end_char="7577">.</TOKEN>
</SEG>
<SEG id="segment-69" start_char="7579" end_char="7688">
<ORIGINAL_TEXT>The ideal treatment for 2019-nCoV may well be a drug like remdesivir plus monoclonal antibodies, Denison says.</ORIGINAL_TEXT>
<TOKEN id="token-69-0" pos="word" morph="none" start_char="7579" end_char="7581">The</TOKEN>
<TOKEN id="token-69-1" pos="word" morph="none" start_char="7583" end_char="7587">ideal</TOKEN>
<TOKEN id="token-69-2" pos="word" morph="none" start_char="7589" end_char="7597">treatment</TOKEN>
<TOKEN id="token-69-3" pos="word" morph="none" start_char="7599" end_char="7601">for</TOKEN>
<TOKEN id="token-69-4" pos="unknown" morph="none" start_char="7603" end_char="7611">2019-nCoV</TOKEN>
<TOKEN id="token-69-5" pos="word" morph="none" start_char="7613" end_char="7615">may</TOKEN>
<TOKEN id="token-69-6" pos="word" morph="none" start_char="7617" end_char="7620">well</TOKEN>
<TOKEN id="token-69-7" pos="word" morph="none" start_char="7622" end_char="7623">be</TOKEN>
<TOKEN id="token-69-8" pos="word" morph="none" start_char="7625" end_char="7625">a</TOKEN>
<TOKEN id="token-69-9" pos="word" morph="none" start_char="7627" end_char="7630">drug</TOKEN>
<TOKEN id="token-69-10" pos="word" morph="none" start_char="7632" end_char="7635">like</TOKEN>
<TOKEN id="token-69-11" pos="word" morph="none" start_char="7637" end_char="7646">remdesivir</TOKEN>
<TOKEN id="token-69-12" pos="word" morph="none" start_char="7648" end_char="7651">plus</TOKEN>
<TOKEN id="token-69-13" pos="word" morph="none" start_char="7653" end_char="7662">monoclonal</TOKEN>
<TOKEN id="token-69-14" pos="word" morph="none" start_char="7664" end_char="7673">antibodies</TOKEN>
<TOKEN id="token-69-15" pos="punct" morph="none" start_char="7674" end_char="7674">,</TOKEN>
<TOKEN id="token-69-16" pos="word" morph="none" start_char="7676" end_char="7682">Denison</TOKEN>
<TOKEN id="token-69-17" pos="word" morph="none" start_char="7684" end_char="7687">says</TOKEN>
<TOKEN id="token-69-18" pos="punct" morph="none" start_char="7688" end_char="7688">.</TOKEN>
</SEG>
<SEG id="segment-70" start_char="7690" end_char="7767">
<ORIGINAL_TEXT>"The idea of using those in combination would have profoundly good prospects."</ORIGINAL_TEXT>
<TOKEN id="token-70-0" pos="punct" morph="none" start_char="7690" end_char="7690">"</TOKEN>
<TOKEN id="token-70-1" pos="word" morph="none" start_char="7691" end_char="7693">The</TOKEN>
<TOKEN id="token-70-2" pos="word" morph="none" start_char="7695" end_char="7698">idea</TOKEN>
<TOKEN id="token-70-3" pos="word" morph="none" start_char="7700" end_char="7701">of</TOKEN>
<TOKEN id="token-70-4" pos="word" morph="none" start_char="7703" end_char="7707">using</TOKEN>
<TOKEN id="token-70-5" pos="word" morph="none" start_char="7709" end_char="7713">those</TOKEN>
<TOKEN id="token-70-6" pos="word" morph="none" start_char="7715" end_char="7716">in</TOKEN>
<TOKEN id="token-70-7" pos="word" morph="none" start_char="7718" end_char="7728">combination</TOKEN>
<TOKEN id="token-70-8" pos="word" morph="none" start_char="7730" end_char="7734">would</TOKEN>
<TOKEN id="token-70-9" pos="word" morph="none" start_char="7736" end_char="7739">have</TOKEN>
<TOKEN id="token-70-10" pos="word" morph="none" start_char="7741" end_char="7750">profoundly</TOKEN>
<TOKEN id="token-70-11" pos="word" morph="none" start_char="7752" end_char="7755">good</TOKEN>
<TOKEN id="token-70-12" pos="word" morph="none" start_char="7757" end_char="7765">prospects</TOKEN>
<TOKEN id="token-70-13" pos="punct" morph="none" start_char="7766" end_char="7767">."</TOKEN>
</SEG>
<SEG id="segment-71" start_char="7770" end_char="7803">
<ORIGINAL_TEXT>Can Vaccines be Developed in Time?</ORIGINAL_TEXT>
<TOKEN id="token-71-0" pos="word" morph="none" start_char="7770" end_char="7772">Can</TOKEN>
<TOKEN id="token-71-1" pos="word" morph="none" start_char="7774" end_char="7781">Vaccines</TOKEN>
<TOKEN id="token-71-2" pos="word" morph="none" start_char="7783" end_char="7784">be</TOKEN>
<TOKEN id="token-71-3" pos="word" morph="none" start_char="7786" end_char="7794">Developed</TOKEN>
<TOKEN id="token-71-4" pos="word" morph="none" start_char="7796" end_char="7797">in</TOKEN>
<TOKEN id="token-71-5" pos="word" morph="none" start_char="7799" end_char="7802">Time</TOKEN>
<TOKEN id="token-71-6" pos="punct" morph="none" start_char="7803" end_char="7803">?</TOKEN>
</SEG>
<SEG id="segment-72" start_char="7807" end_char="7895">
<ORIGINAL_TEXT>In the stock pandemic movie, scientists develop a vaccine just in time to save the world.</ORIGINAL_TEXT>
<TOKEN id="token-72-0" pos="word" morph="none" start_char="7807" end_char="7808">In</TOKEN>
<TOKEN id="token-72-1" pos="word" morph="none" start_char="7810" end_char="7812">the</TOKEN>
<TOKEN id="token-72-2" pos="word" morph="none" start_char="7814" end_char="7818">stock</TOKEN>
<TOKEN id="token-72-3" pos="word" morph="none" start_char="7820" end_char="7827">pandemic</TOKEN>
<TOKEN id="token-72-4" pos="word" morph="none" start_char="7829" end_char="7833">movie</TOKEN>
<TOKEN id="token-72-5" pos="punct" morph="none" start_char="7834" end_char="7834">,</TOKEN>
<TOKEN id="token-72-6" pos="word" morph="none" start_char="7836" end_char="7845">scientists</TOKEN>
<TOKEN id="token-72-7" pos="word" morph="none" start_char="7847" end_char="7853">develop</TOKEN>
<TOKEN id="token-72-8" pos="word" morph="none" start_char="7855" end_char="7855">a</TOKEN>
<TOKEN id="token-72-9" pos="word" morph="none" start_char="7857" end_char="7863">vaccine</TOKEN>
<TOKEN id="token-72-10" pos="word" morph="none" start_char="7865" end_char="7868">just</TOKEN>
<TOKEN id="token-72-11" pos="word" morph="none" start_char="7870" end_char="7871">in</TOKEN>
<TOKEN id="token-72-12" pos="word" morph="none" start_char="7873" end_char="7876">time</TOKEN>
<TOKEN id="token-72-13" pos="word" morph="none" start_char="7878" end_char="7879">to</TOKEN>
<TOKEN id="token-72-14" pos="word" morph="none" start_char="7881" end_char="7884">save</TOKEN>
<TOKEN id="token-72-15" pos="word" morph="none" start_char="7886" end_char="7888">the</TOKEN>
<TOKEN id="token-72-16" pos="word" morph="none" start_char="7890" end_char="7894">world</TOKEN>
<TOKEN id="token-72-17" pos="punct" morph="none" start_char="7895" end_char="7895">.</TOKEN>
</SEG>
<SEG id="segment-73" start_char="7897" end_char="8011">
<ORIGINAL_TEXT>In real life, new vaccines have never been developed fast enough to have a significant impact on an emerging virus.</ORIGINAL_TEXT>
<TOKEN id="token-73-0" pos="word" morph="none" start_char="7897" end_char="7898">In</TOKEN>
<TOKEN id="token-73-1" pos="word" morph="none" start_char="7900" end_char="7903">real</TOKEN>
<TOKEN id="token-73-2" pos="word" morph="none" start_char="7905" end_char="7908">life</TOKEN>
<TOKEN id="token-73-3" pos="punct" morph="none" start_char="7909" end_char="7909">,</TOKEN>
<TOKEN id="token-73-4" pos="word" morph="none" start_char="7911" end_char="7913">new</TOKEN>
<TOKEN id="token-73-5" pos="word" morph="none" start_char="7915" end_char="7922">vaccines</TOKEN>
<TOKEN id="token-73-6" pos="word" morph="none" start_char="7924" end_char="7927">have</TOKEN>
<TOKEN id="token-73-7" pos="word" morph="none" start_char="7929" end_char="7933">never</TOKEN>
<TOKEN id="token-73-8" pos="word" morph="none" start_char="7935" end_char="7938">been</TOKEN>
<TOKEN id="token-73-9" pos="word" morph="none" start_char="7940" end_char="7948">developed</TOKEN>
<TOKEN id="token-73-10" pos="word" morph="none" start_char="7950" end_char="7953">fast</TOKEN>
<TOKEN id="token-73-11" pos="word" morph="none" start_char="7955" end_char="7960">enough</TOKEN>
<TOKEN id="token-73-12" pos="word" morph="none" start_char="7962" end_char="7963">to</TOKEN>
<TOKEN id="token-73-13" pos="word" morph="none" start_char="7965" end_char="7968">have</TOKEN>
<TOKEN id="token-73-14" pos="word" morph="none" start_char="7970" end_char="7970">a</TOKEN>
<TOKEN id="token-73-15" pos="word" morph="none" start_char="7972" end_char="7982">significant</TOKEN>
<TOKEN id="token-73-16" pos="word" morph="none" start_char="7984" end_char="7989">impact</TOKEN>
<TOKEN id="token-73-17" pos="word" morph="none" start_char="7991" end_char="7992">on</TOKEN>
<TOKEN id="token-73-18" pos="word" morph="none" start_char="7994" end_char="7995">an</TOKEN>
<TOKEN id="token-73-19" pos="word" morph="none" start_char="7997" end_char="8004">emerging</TOKEN>
<TOKEN id="token-73-20" pos="word" morph="none" start_char="8006" end_char="8010">virus</TOKEN>
<TOKEN id="token-73-21" pos="punct" morph="none" start_char="8011" end_char="8011">.</TOKEN>
</SEG>
<SEG id="segment-74" start_char="8013" end_char="8091">
<ORIGINAL_TEXT>But in the case of 2019-nCoV, scientists are trying to work at Hollywood speed.</ORIGINAL_TEXT>
<TOKEN id="token-74-0" pos="word" morph="none" start_char="8013" end_char="8015">But</TOKEN>
<TOKEN id="token-74-1" pos="word" morph="none" start_char="8017" end_char="8018">in</TOKEN>
<TOKEN id="token-74-2" pos="word" morph="none" start_char="8020" end_char="8022">the</TOKEN>
<TOKEN id="token-74-3" pos="word" morph="none" start_char="8024" end_char="8027">case</TOKEN>
<TOKEN id="token-74-4" pos="word" morph="none" start_char="8029" end_char="8030">of</TOKEN>
<TOKEN id="token-74-5" pos="unknown" morph="none" start_char="8032" end_char="8040">2019-nCoV</TOKEN>
<TOKEN id="token-74-6" pos="punct" morph="none" start_char="8041" end_char="8041">,</TOKEN>
<TOKEN id="token-74-7" pos="word" morph="none" start_char="8043" end_char="8052">scientists</TOKEN>
<TOKEN id="token-74-8" pos="word" morph="none" start_char="8054" end_char="8056">are</TOKEN>
<TOKEN id="token-74-9" pos="word" morph="none" start_char="8058" end_char="8063">trying</TOKEN>
<TOKEN id="token-74-10" pos="word" morph="none" start_char="8065" end_char="8066">to</TOKEN>
<TOKEN id="token-74-11" pos="word" morph="none" start_char="8068" end_char="8071">work</TOKEN>
<TOKEN id="token-74-12" pos="word" morph="none" start_char="8073" end_char="8074">at</TOKEN>
<TOKEN id="token-74-13" pos="word" morph="none" start_char="8076" end_char="8084">Hollywood</TOKEN>
<TOKEN id="token-74-14" pos="word" morph="none" start_char="8086" end_char="8090">speed</TOKEN>
<TOKEN id="token-74-15" pos="punct" morph="none" start_char="8091" end_char="8091">.</TOKEN>
</SEG>
<SEG id="segment-75" start_char="8094" end_char="8380">
<ORIGINAL_TEXT>The Coalition for Epidemic Preparedness Innovations (CEPI), a nonprofit formed in 2016 to fund and shepherd the development of new vaccines against emerging infectious diseases, has already given two companies and an academic group a total of $12.5 million to develop 2019-nCoV vaccines.</ORIGINAL_TEXT>
<TOKEN id="token-75-0" pos="word" morph="none" start_char="8094" end_char="8096">The</TOKEN>
<TOKEN id="token-75-1" pos="word" morph="none" start_char="8098" end_char="8106">Coalition</TOKEN>
<TOKEN id="token-75-2" pos="word" morph="none" start_char="8108" end_char="8110">for</TOKEN>
<TOKEN id="token-75-3" pos="word" morph="none" start_char="8112" end_char="8119">Epidemic</TOKEN>
<TOKEN id="token-75-4" pos="word" morph="none" start_char="8121" end_char="8132">Preparedness</TOKEN>
<TOKEN id="token-75-5" pos="word" morph="none" start_char="8134" end_char="8144">Innovations</TOKEN>
<TOKEN id="token-75-6" pos="punct" morph="none" start_char="8146" end_char="8146">(</TOKEN>
<TOKEN id="token-75-7" pos="word" morph="none" start_char="8147" end_char="8150">CEPI</TOKEN>
<TOKEN id="token-75-8" pos="punct" morph="none" start_char="8151" end_char="8152">),</TOKEN>
<TOKEN id="token-75-9" pos="word" morph="none" start_char="8154" end_char="8154">a</TOKEN>
<TOKEN id="token-75-10" pos="word" morph="none" start_char="8156" end_char="8164">nonprofit</TOKEN>
<TOKEN id="token-75-11" pos="word" morph="none" start_char="8166" end_char="8171">formed</TOKEN>
<TOKEN id="token-75-12" pos="word" morph="none" start_char="8173" end_char="8174">in</TOKEN>
<TOKEN id="token-75-13" pos="word" morph="none" start_char="8176" end_char="8179">2016</TOKEN>
<TOKEN id="token-75-14" pos="word" morph="none" start_char="8181" end_char="8182">to</TOKEN>
<TOKEN id="token-75-15" pos="word" morph="none" start_char="8184" end_char="8187">fund</TOKEN>
<TOKEN id="token-75-16" pos="word" morph="none" start_char="8189" end_char="8191">and</TOKEN>
<TOKEN id="token-75-17" pos="word" morph="none" start_char="8193" end_char="8200">shepherd</TOKEN>
<TOKEN id="token-75-18" pos="word" morph="none" start_char="8202" end_char="8204">the</TOKEN>
<TOKEN id="token-75-19" pos="word" morph="none" start_char="8206" end_char="8216">development</TOKEN>
<TOKEN id="token-75-20" pos="word" morph="none" start_char="8218" end_char="8219">of</TOKEN>
<TOKEN id="token-75-21" pos="word" morph="none" start_char="8221" end_char="8223">new</TOKEN>
<TOKEN id="token-75-22" pos="word" morph="none" start_char="8225" end_char="8232">vaccines</TOKEN>
<TOKEN id="token-75-23" pos="word" morph="none" start_char="8234" end_char="8240">against</TOKEN>
<TOKEN id="token-75-24" pos="word" morph="none" start_char="8242" end_char="8249">emerging</TOKEN>
<TOKEN id="token-75-25" pos="word" morph="none" start_char="8251" end_char="8260">infectious</TOKEN>
<TOKEN id="token-75-26" pos="word" morph="none" start_char="8262" end_char="8269">diseases</TOKEN>
<TOKEN id="token-75-27" pos="punct" morph="none" start_char="8270" end_char="8270">,</TOKEN>
<TOKEN id="token-75-28" pos="word" morph="none" start_char="8272" end_char="8274">has</TOKEN>
<TOKEN id="token-75-29" pos="word" morph="none" start_char="8276" end_char="8282">already</TOKEN>
<TOKEN id="token-75-30" pos="word" morph="none" start_char="8284" end_char="8288">given</TOKEN>
<TOKEN id="token-75-31" pos="word" morph="none" start_char="8290" end_char="8292">two</TOKEN>
<TOKEN id="token-75-32" pos="word" morph="none" start_char="8294" end_char="8302">companies</TOKEN>
<TOKEN id="token-75-33" pos="word" morph="none" start_char="8304" end_char="8306">and</TOKEN>
<TOKEN id="token-75-34" pos="word" morph="none" start_char="8308" end_char="8309">an</TOKEN>
<TOKEN id="token-75-35" pos="word" morph="none" start_char="8311" end_char="8318">academic</TOKEN>
<TOKEN id="token-75-36" pos="word" morph="none" start_char="8320" end_char="8324">group</TOKEN>
<TOKEN id="token-75-37" pos="word" morph="none" start_char="8326" end_char="8326">a</TOKEN>
<TOKEN id="token-75-38" pos="word" morph="none" start_char="8328" end_char="8332">total</TOKEN>
<TOKEN id="token-75-39" pos="word" morph="none" start_char="8334" end_char="8335">of</TOKEN>
<TOKEN id="token-75-40" pos="unknown" morph="none" start_char="8337" end_char="8341">$12.5</TOKEN>
<TOKEN id="token-75-41" pos="word" morph="none" start_char="8343" end_char="8349">million</TOKEN>
<TOKEN id="token-75-42" pos="word" morph="none" start_char="8351" end_char="8352">to</TOKEN>
<TOKEN id="token-75-43" pos="word" morph="none" start_char="8354" end_char="8360">develop</TOKEN>
<TOKEN id="token-75-44" pos="unknown" morph="none" start_char="8362" end_char="8370">2019-nCoV</TOKEN>
<TOKEN id="token-75-45" pos="word" morph="none" start_char="8372" end_char="8379">vaccines</TOKEN>
<TOKEN id="token-75-46" pos="punct" morph="none" start_char="8380" end_char="8380">.</TOKEN>
</SEG>
<SEG id="segment-76" start_char="8382" end_char="8476">
<ORIGINAL_TEXT>The efforts began hours after Chinese researchers first published a viral sequence 3 weeks ago.</ORIGINAL_TEXT>
<TOKEN id="token-76-0" pos="word" morph="none" start_char="8382" end_char="8384">The</TOKEN>
<TOKEN id="token-76-1" pos="word" morph="none" start_char="8386" end_char="8392">efforts</TOKEN>
<TOKEN id="token-76-2" pos="word" morph="none" start_char="8394" end_char="8398">began</TOKEN>
<TOKEN id="token-76-3" pos="word" morph="none" start_char="8400" end_char="8404">hours</TOKEN>
<TOKEN id="token-76-4" pos="word" morph="none" start_char="8406" end_char="8410">after</TOKEN>
<TOKEN id="token-76-5" pos="word" morph="none" start_char="8412" end_char="8418">Chinese</TOKEN>
<TOKEN id="token-76-6" pos="word" morph="none" start_char="8420" end_char="8430">researchers</TOKEN>
<TOKEN id="token-76-7" pos="word" morph="none" start_char="8432" end_char="8436">first</TOKEN>
<TOKEN id="token-76-8" pos="word" morph="none" start_char="8438" end_char="8446">published</TOKEN>
<TOKEN id="token-76-9" pos="word" morph="none" start_char="8448" end_char="8448">a</TOKEN>
<TOKEN id="token-76-10" pos="word" morph="none" start_char="8450" end_char="8454">viral</TOKEN>
<TOKEN id="token-76-11" pos="word" morph="none" start_char="8456" end_char="8463">sequence</TOKEN>
<TOKEN id="token-76-12" pos="word" morph="none" start_char="8465" end_char="8465">3</TOKEN>
<TOKEN id="token-76-13" pos="word" morph="none" start_char="8467" end_char="8471">weeks</TOKEN>
<TOKEN id="token-76-14" pos="word" morph="none" start_char="8473" end_char="8475">ago</TOKEN>
<TOKEN id="token-76-15" pos="punct" morph="none" start_char="8476" end_char="8476">.</TOKEN>
</SEG>
<SEG id="segment-77" start_char="8479" end_char="8683">
<ORIGINAL_TEXT>One is a collaboration between the U.S. National Institute of Allergy and Infectious Diseases (NIAID) and U.S. biotech Moderna, which makes vaccines by converting viral sequences into messenger RNA (mRNA).</ORIGINAL_TEXT>
<TOKEN id="token-77-0" pos="word" morph="none" start_char="8479" end_char="8481">One</TOKEN>
<TOKEN id="token-77-1" pos="word" morph="none" start_char="8483" end_char="8484">is</TOKEN>
<TOKEN id="token-77-2" pos="word" morph="none" start_char="8486" end_char="8486">a</TOKEN>
<TOKEN id="token-77-3" pos="word" morph="none" start_char="8488" end_char="8500">collaboration</TOKEN>
<TOKEN id="token-77-4" pos="word" morph="none" start_char="8502" end_char="8508">between</TOKEN>
<TOKEN id="token-77-5" pos="word" morph="none" start_char="8510" end_char="8512">the</TOKEN>
<TOKEN id="token-77-6" pos="unknown" morph="none" start_char="8514" end_char="8516">U.S</TOKEN>
<TOKEN id="token-77-7" pos="punct" morph="none" start_char="8517" end_char="8517">.</TOKEN>
<TOKEN id="token-77-8" pos="word" morph="none" start_char="8519" end_char="8526">National</TOKEN>
<TOKEN id="token-77-9" pos="word" morph="none" start_char="8528" end_char="8536">Institute</TOKEN>
<TOKEN id="token-77-10" pos="word" morph="none" start_char="8538" end_char="8539">of</TOKEN>
<TOKEN id="token-77-11" pos="word" morph="none" start_char="8541" end_char="8547">Allergy</TOKEN>
<TOKEN id="token-77-12" pos="word" morph="none" start_char="8549" end_char="8551">and</TOKEN>
<TOKEN id="token-77-13" pos="word" morph="none" start_char="8553" end_char="8562">Infectious</TOKEN>
<TOKEN id="token-77-14" pos="word" morph="none" start_char="8564" end_char="8571">Diseases</TOKEN>
<TOKEN id="token-77-15" pos="punct" morph="none" start_char="8573" end_char="8573">(</TOKEN>
<TOKEN id="token-77-16" pos="word" morph="none" start_char="8574" end_char="8578">NIAID</TOKEN>
<TOKEN id="token-77-17" pos="punct" morph="none" start_char="8579" end_char="8579">)</TOKEN>
<TOKEN id="token-77-18" pos="word" morph="none" start_char="8581" end_char="8583">and</TOKEN>
<TOKEN id="token-77-19" pos="unknown" morph="none" start_char="8585" end_char="8587">U.S</TOKEN>
<TOKEN id="token-77-20" pos="punct" morph="none" start_char="8588" end_char="8588">.</TOKEN>
<TOKEN id="token-77-21" pos="word" morph="none" start_char="8590" end_char="8596">biotech</TOKEN>
<TOKEN id="token-77-22" pos="word" morph="none" start_char="8598" end_char="8604">Moderna</TOKEN>
<TOKEN id="token-77-23" pos="punct" morph="none" start_char="8605" end_char="8605">,</TOKEN>
<TOKEN id="token-77-24" pos="word" morph="none" start_char="8607" end_char="8611">which</TOKEN>
<TOKEN id="token-77-25" pos="word" morph="none" start_char="8613" end_char="8617">makes</TOKEN>
<TOKEN id="token-77-26" pos="word" morph="none" start_char="8619" end_char="8626">vaccines</TOKEN>
<TOKEN id="token-77-27" pos="word" morph="none" start_char="8628" end_char="8629">by</TOKEN>
<TOKEN id="token-77-28" pos="word" morph="none" start_char="8631" end_char="8640">converting</TOKEN>
<TOKEN id="token-77-29" pos="word" morph="none" start_char="8642" end_char="8646">viral</TOKEN>
<TOKEN id="token-77-30" pos="word" morph="none" start_char="8648" end_char="8656">sequences</TOKEN>
<TOKEN id="token-77-31" pos="word" morph="none" start_char="8658" end_char="8661">into</TOKEN>
<TOKEN id="token-77-32" pos="word" morph="none" start_char="8663" end_char="8671">messenger</TOKEN>
<TOKEN id="token-77-33" pos="word" morph="none" start_char="8673" end_char="8675">RNA</TOKEN>
<TOKEN id="token-77-34" pos="punct" morph="none" start_char="8677" end_char="8677">(</TOKEN>
<TOKEN id="token-77-35" pos="word" morph="none" start_char="8678" end_char="8681">mRNA</TOKEN>
<TOKEN id="token-77-36" pos="punct" morph="none" start_char="8682" end_char="8683">).</TOKEN>
</SEG>
<SEG id="segment-78" start_char="8685" end_char="8796">
<ORIGINAL_TEXT>(When injected into the body, mRNA causes the body to produce a viral protein, which triggers immune responses.)</ORIGINAL_TEXT>
<TOKEN id="token-78-0" pos="punct" morph="none" start_char="8685" end_char="8685">(</TOKEN>
<TOKEN id="token-78-1" pos="word" morph="none" start_char="8686" end_char="8689">When</TOKEN>
<TOKEN id="token-78-2" pos="word" morph="none" start_char="8691" end_char="8698">injected</TOKEN>
<TOKEN id="token-78-3" pos="word" morph="none" start_char="8700" end_char="8703">into</TOKEN>
<TOKEN id="token-78-4" pos="word" morph="none" start_char="8705" end_char="8707">the</TOKEN>
<TOKEN id="token-78-5" pos="word" morph="none" start_char="8709" end_char="8712">body</TOKEN>
<TOKEN id="token-78-6" pos="punct" morph="none" start_char="8713" end_char="8713">,</TOKEN>
<TOKEN id="token-78-7" pos="word" morph="none" start_char="8715" end_char="8718">mRNA</TOKEN>
<TOKEN id="token-78-8" pos="word" morph="none" start_char="8720" end_char="8725">causes</TOKEN>
<TOKEN id="token-78-9" pos="word" morph="none" start_char="8727" end_char="8729">the</TOKEN>
<TOKEN id="token-78-10" pos="word" morph="none" start_char="8731" end_char="8734">body</TOKEN>
<TOKEN id="token-78-11" pos="word" morph="none" start_char="8736" end_char="8737">to</TOKEN>
<TOKEN id="token-78-12" pos="word" morph="none" start_char="8739" end_char="8745">produce</TOKEN>
<TOKEN id="token-78-13" pos="word" morph="none" start_char="8747" end_char="8747">a</TOKEN>
<TOKEN id="token-78-14" pos="word" morph="none" start_char="8749" end_char="8753">viral</TOKEN>
<TOKEN id="token-78-15" pos="word" morph="none" start_char="8755" end_char="8761">protein</TOKEN>
<TOKEN id="token-78-16" pos="punct" morph="none" start_char="8762" end_char="8762">,</TOKEN>
<TOKEN id="token-78-17" pos="word" morph="none" start_char="8764" end_char="8768">which</TOKEN>
<TOKEN id="token-78-18" pos="word" morph="none" start_char="8770" end_char="8777">triggers</TOKEN>
<TOKEN id="token-78-19" pos="word" morph="none" start_char="8779" end_char="8784">immune</TOKEN>
<TOKEN id="token-78-20" pos="word" morph="none" start_char="8786" end_char="8794">responses</TOKEN>
<TOKEN id="token-78-21" pos="punct" morph="none" start_char="8795" end_char="8796">.)</TOKEN>
</SEG>
<SEG id="segment-79" start_char="8798" end_char="9029">
<ORIGINAL_TEXT>Moderna and NIAID have worked on a vaccine against MERS that consists of mRNA coding for a protein on the viral surface called the spike; in theory, all the team needs to do now is swap in the genetic sequence for 2019-nCoV's spike.</ORIGINAL_TEXT>
<TOKEN id="token-79-0" pos="word" morph="none" start_char="8798" end_char="8804">Moderna</TOKEN>
<TOKEN id="token-79-1" pos="word" morph="none" start_char="8806" end_char="8808">and</TOKEN>
<TOKEN id="token-79-2" pos="word" morph="none" start_char="8810" end_char="8814">NIAID</TOKEN>
<TOKEN id="token-79-3" pos="word" morph="none" start_char="8816" end_char="8819">have</TOKEN>
<TOKEN id="token-79-4" pos="word" morph="none" start_char="8821" end_char="8826">worked</TOKEN>
<TOKEN id="token-79-5" pos="word" morph="none" start_char="8828" end_char="8829">on</TOKEN>
<TOKEN id="token-79-6" pos="word" morph="none" start_char="8831" end_char="8831">a</TOKEN>
<TOKEN id="token-79-7" pos="word" morph="none" start_char="8833" end_char="8839">vaccine</TOKEN>
<TOKEN id="token-79-8" pos="word" morph="none" start_char="8841" end_char="8847">against</TOKEN>
<TOKEN id="token-79-9" pos="word" morph="none" start_char="8849" end_char="8852">MERS</TOKEN>
<TOKEN id="token-79-10" pos="word" morph="none" start_char="8854" end_char="8857">that</TOKEN>
<TOKEN id="token-79-11" pos="word" morph="none" start_char="8859" end_char="8866">consists</TOKEN>
<TOKEN id="token-79-12" pos="word" morph="none" start_char="8868" end_char="8869">of</TOKEN>
<TOKEN id="token-79-13" pos="word" morph="none" start_char="8871" end_char="8874">mRNA</TOKEN>
<TOKEN id="token-79-14" pos="word" morph="none" start_char="8876" end_char="8881">coding</TOKEN>
<TOKEN id="token-79-15" pos="word" morph="none" start_char="8883" end_char="8885">for</TOKEN>
<TOKEN id="token-79-16" pos="word" morph="none" start_char="8887" end_char="8887">a</TOKEN>
<TOKEN id="token-79-17" pos="word" morph="none" start_char="8889" end_char="8895">protein</TOKEN>
<TOKEN id="token-79-18" pos="word" morph="none" start_char="8897" end_char="8898">on</TOKEN>
<TOKEN id="token-79-19" pos="word" morph="none" start_char="8900" end_char="8902">the</TOKEN>
<TOKEN id="token-79-20" pos="word" morph="none" start_char="8904" end_char="8908">viral</TOKEN>
<TOKEN id="token-79-21" pos="word" morph="none" start_char="8910" end_char="8916">surface</TOKEN>
<TOKEN id="token-79-22" pos="word" morph="none" start_char="8918" end_char="8923">called</TOKEN>
<TOKEN id="token-79-23" pos="word" morph="none" start_char="8925" end_char="8927">the</TOKEN>
<TOKEN id="token-79-24" pos="word" morph="none" start_char="8929" end_char="8933">spike</TOKEN>
<TOKEN id="token-79-25" pos="punct" morph="none" start_char="8934" end_char="8934">;</TOKEN>
<TOKEN id="token-79-26" pos="word" morph="none" start_char="8936" end_char="8937">in</TOKEN>
<TOKEN id="token-79-27" pos="word" morph="none" start_char="8939" end_char="8944">theory</TOKEN>
<TOKEN id="token-79-28" pos="punct" morph="none" start_char="8945" end_char="8945">,</TOKEN>
<TOKEN id="token-79-29" pos="word" morph="none" start_char="8947" end_char="8949">all</TOKEN>
<TOKEN id="token-79-30" pos="word" morph="none" start_char="8951" end_char="8953">the</TOKEN>
<TOKEN id="token-79-31" pos="word" morph="none" start_char="8955" end_char="8958">team</TOKEN>
<TOKEN id="token-79-32" pos="word" morph="none" start_char="8960" end_char="8964">needs</TOKEN>
<TOKEN id="token-79-33" pos="word" morph="none" start_char="8966" end_char="8967">to</TOKEN>
<TOKEN id="token-79-34" pos="word" morph="none" start_char="8969" end_char="8970">do</TOKEN>
<TOKEN id="token-79-35" pos="word" morph="none" start_char="8972" end_char="8974">now</TOKEN>
<TOKEN id="token-79-36" pos="word" morph="none" start_char="8976" end_char="8977">is</TOKEN>
<TOKEN id="token-79-37" pos="word" morph="none" start_char="8979" end_char="8982">swap</TOKEN>
<TOKEN id="token-79-38" pos="word" morph="none" start_char="8984" end_char="8985">in</TOKEN>
<TOKEN id="token-79-39" pos="word" morph="none" start_char="8987" end_char="8989">the</TOKEN>
<TOKEN id="token-79-40" pos="word" morph="none" start_char="8991" end_char="8997">genetic</TOKEN>
<TOKEN id="token-79-41" pos="word" morph="none" start_char="8999" end_char="9006">sequence</TOKEN>
<TOKEN id="token-79-42" pos="word" morph="none" start_char="9008" end_char="9010">for</TOKEN>
<TOKEN id="token-79-43" pos="unknown" morph="none" start_char="9012" end_char="9022">2019-nCoV's</TOKEN>
<TOKEN id="token-79-44" pos="word" morph="none" start_char="9024" end_char="9028">spike</TOKEN>
<TOKEN id="token-79-45" pos="punct" morph="none" start_char="9029" end_char="9029">.</TOKEN>
</SEG>
<SEG id="segment-80" start_char="9032" end_char="9136">
<ORIGINAL_TEXT>CEPI funded a second company, Inovio, to produce vaccines that work in a similar way but are made of DNA.</ORIGINAL_TEXT>
<TOKEN id="token-80-0" pos="word" morph="none" start_char="9032" end_char="9035">CEPI</TOKEN>
<TOKEN id="token-80-1" pos="word" morph="none" start_char="9037" end_char="9042">funded</TOKEN>
<TOKEN id="token-80-2" pos="word" morph="none" start_char="9044" end_char="9044">a</TOKEN>
<TOKEN id="token-80-3" pos="word" morph="none" start_char="9046" end_char="9051">second</TOKEN>
<TOKEN id="token-80-4" pos="word" morph="none" start_char="9053" end_char="9059">company</TOKEN>
<TOKEN id="token-80-5" pos="punct" morph="none" start_char="9060" end_char="9060">,</TOKEN>
<TOKEN id="token-80-6" pos="word" morph="none" start_char="9062" end_char="9067">Inovio</TOKEN>
<TOKEN id="token-80-7" pos="punct" morph="none" start_char="9068" end_char="9068">,</TOKEN>
<TOKEN id="token-80-8" pos="word" morph="none" start_char="9070" end_char="9071">to</TOKEN>
<TOKEN id="token-80-9" pos="word" morph="none" start_char="9073" end_char="9079">produce</TOKEN>
<TOKEN id="token-80-10" pos="word" morph="none" start_char="9081" end_char="9088">vaccines</TOKEN>
<TOKEN id="token-80-11" pos="word" morph="none" start_char="9090" end_char="9093">that</TOKEN>
<TOKEN id="token-80-12" pos="word" morph="none" start_char="9095" end_char="9098">work</TOKEN>
<TOKEN id="token-80-13" pos="word" morph="none" start_char="9100" end_char="9101">in</TOKEN>
<TOKEN id="token-80-14" pos="word" morph="none" start_char="9103" end_char="9103">a</TOKEN>
<TOKEN id="token-80-15" pos="word" morph="none" start_char="9105" end_char="9111">similar</TOKEN>
<TOKEN id="token-80-16" pos="word" morph="none" start_char="9113" end_char="9115">way</TOKEN>
<TOKEN id="token-80-17" pos="word" morph="none" start_char="9117" end_char="9119">but</TOKEN>
<TOKEN id="token-80-18" pos="word" morph="none" start_char="9121" end_char="9123">are</TOKEN>
<TOKEN id="token-80-19" pos="word" morph="none" start_char="9125" end_char="9128">made</TOKEN>
<TOKEN id="token-80-20" pos="word" morph="none" start_char="9130" end_char="9131">of</TOKEN>
<TOKEN id="token-80-21" pos="word" morph="none" start_char="9133" end_char="9135">DNA</TOKEN>
<TOKEN id="token-80-22" pos="punct" morph="none" start_char="9136" end_char="9136">.</TOKEN>
</SEG>
<SEG id="segment-81" start_char="9138" end_char="9250">
<ORIGINAL_TEXT>It, too, has a template for a 2019-nCoV vaccine: another candidate MERS vaccine that relies on the spike protein.</ORIGINAL_TEXT>
<TOKEN id="token-81-0" pos="word" morph="none" start_char="9138" end_char="9139">It</TOKEN>
<TOKEN id="token-81-1" pos="punct" morph="none" start_char="9140" end_char="9140">,</TOKEN>
<TOKEN id="token-81-2" pos="word" morph="none" start_char="9142" end_char="9144">too</TOKEN>
<TOKEN id="token-81-3" pos="punct" morph="none" start_char="9145" end_char="9145">,</TOKEN>
<TOKEN id="token-81-4" pos="word" morph="none" start_char="9147" end_char="9149">has</TOKEN>
<TOKEN id="token-81-5" pos="word" morph="none" start_char="9151" end_char="9151">a</TOKEN>
<TOKEN id="token-81-6" pos="word" morph="none" start_char="9153" end_char="9160">template</TOKEN>
<TOKEN id="token-81-7" pos="word" morph="none" start_char="9162" end_char="9164">for</TOKEN>
<TOKEN id="token-81-8" pos="word" morph="none" start_char="9166" end_char="9166">a</TOKEN>
<TOKEN id="token-81-9" pos="unknown" morph="none" start_char="9168" end_char="9176">2019-nCoV</TOKEN>
<TOKEN id="token-81-10" pos="word" morph="none" start_char="9178" end_char="9184">vaccine</TOKEN>
<TOKEN id="token-81-11" pos="punct" morph="none" start_char="9185" end_char="9185">:</TOKEN>
<TOKEN id="token-81-12" pos="word" morph="none" start_char="9187" end_char="9193">another</TOKEN>
<TOKEN id="token-81-13" pos="word" morph="none" start_char="9195" end_char="9203">candidate</TOKEN>
<TOKEN id="token-81-14" pos="word" morph="none" start_char="9205" end_char="9208">MERS</TOKEN>
<TOKEN id="token-81-15" pos="word" morph="none" start_char="9210" end_char="9216">vaccine</TOKEN>
<TOKEN id="token-81-16" pos="word" morph="none" start_char="9218" end_char="9221">that</TOKEN>
<TOKEN id="token-81-17" pos="word" morph="none" start_char="9223" end_char="9228">relies</TOKEN>
<TOKEN id="token-81-18" pos="word" morph="none" start_char="9230" end_char="9231">on</TOKEN>
<TOKEN id="token-81-19" pos="word" morph="none" start_char="9233" end_char="9235">the</TOKEN>
<TOKEN id="token-81-20" pos="word" morph="none" start_char="9237" end_char="9241">spike</TOKEN>
<TOKEN id="token-81-21" pos="word" morph="none" start_char="9243" end_char="9249">protein</TOKEN>
<TOKEN id="token-81-22" pos="punct" morph="none" start_char="9250" end_char="9250">.</TOKEN>
</SEG>
<SEG id="segment-82" start_char="9252" end_char="9400">
<ORIGINAL_TEXT>CEPI's third grant went to researchers at the University of Queensland who are developing a vaccine made of viral proteins produced in cell cultures.</ORIGINAL_TEXT>
<TOKEN id="token-82-0" pos="word" morph="none" start_char="9252" end_char="9257">CEPI's</TOKEN>
<TOKEN id="token-82-1" pos="word" morph="none" start_char="9259" end_char="9263">third</TOKEN>
<TOKEN id="token-82-2" pos="word" morph="none" start_char="9265" end_char="9269">grant</TOKEN>
<TOKEN id="token-82-3" pos="word" morph="none" start_char="9271" end_char="9274">went</TOKEN>
<TOKEN id="token-82-4" pos="word" morph="none" start_char="9276" end_char="9277">to</TOKEN>
<TOKEN id="token-82-5" pos="word" morph="none" start_char="9279" end_char="9289">researchers</TOKEN>
<TOKEN id="token-82-6" pos="word" morph="none" start_char="9291" end_char="9292">at</TOKEN>
<TOKEN id="token-82-7" pos="word" morph="none" start_char="9294" end_char="9296">the</TOKEN>
<TOKEN id="token-82-8" pos="word" morph="none" start_char="9298" end_char="9307">University</TOKEN>
<TOKEN id="token-82-9" pos="word" morph="none" start_char="9309" end_char="9310">of</TOKEN>
<TOKEN id="token-82-10" pos="word" morph="none" start_char="9312" end_char="9321">Queensland</TOKEN>
<TOKEN id="token-82-11" pos="word" morph="none" start_char="9323" end_char="9325">who</TOKEN>
<TOKEN id="token-82-12" pos="word" morph="none" start_char="9327" end_char="9329">are</TOKEN>
<TOKEN id="token-82-13" pos="word" morph="none" start_char="9331" end_char="9340">developing</TOKEN>
<TOKEN id="token-82-14" pos="word" morph="none" start_char="9342" end_char="9342">a</TOKEN>
<TOKEN id="token-82-15" pos="word" morph="none" start_char="9344" end_char="9350">vaccine</TOKEN>
<TOKEN id="token-82-16" pos="word" morph="none" start_char="9352" end_char="9355">made</TOKEN>
<TOKEN id="token-82-17" pos="word" morph="none" start_char="9357" end_char="9358">of</TOKEN>
<TOKEN id="token-82-18" pos="word" morph="none" start_char="9360" end_char="9364">viral</TOKEN>
<TOKEN id="token-82-19" pos="word" morph="none" start_char="9366" end_char="9373">proteins</TOKEN>
<TOKEN id="token-82-20" pos="word" morph="none" start_char="9375" end_char="9382">produced</TOKEN>
<TOKEN id="token-82-21" pos="word" morph="none" start_char="9384" end_char="9385">in</TOKEN>
<TOKEN id="token-82-22" pos="word" morph="none" start_char="9387" end_char="9390">cell</TOKEN>
<TOKEN id="token-82-23" pos="word" morph="none" start_char="9392" end_char="9399">cultures</TOKEN>
<TOKEN id="token-82-24" pos="punct" morph="none" start_char="9400" end_char="9400">.</TOKEN>
</SEG>
<SEG id="segment-83" start_char="9402" end_char="9487">
<ORIGINAL_TEXT>Vaccine projects are also underway in mainland China, Hong Kong, Belgium, and Germany.</ORIGINAL_TEXT>
<TOKEN id="token-83-0" pos="word" morph="none" start_char="9402" end_char="9408">Vaccine</TOKEN>
<TOKEN id="token-83-1" pos="word" morph="none" start_char="9410" end_char="9417">projects</TOKEN>
<TOKEN id="token-83-2" pos="word" morph="none" start_char="9419" end_char="9421">are</TOKEN>
<TOKEN id="token-83-3" pos="word" morph="none" start_char="9423" end_char="9426">also</TOKEN>
<TOKEN id="token-83-4" pos="word" morph="none" start_char="9428" end_char="9435">underway</TOKEN>
<TOKEN id="token-83-5" pos="word" morph="none" start_char="9437" end_char="9438">in</TOKEN>
<TOKEN id="token-83-6" pos="word" morph="none" start_char="9440" end_char="9447">mainland</TOKEN>
<TOKEN id="token-83-7" pos="word" morph="none" start_char="9449" end_char="9453">China</TOKEN>
<TOKEN id="token-83-8" pos="punct" morph="none" start_char="9454" end_char="9454">,</TOKEN>
<TOKEN id="token-83-9" pos="word" morph="none" start_char="9456" end_char="9459">Hong</TOKEN>
<TOKEN id="token-83-10" pos="word" morph="none" start_char="9461" end_char="9464">Kong</TOKEN>
<TOKEN id="token-83-11" pos="punct" morph="none" start_char="9465" end_char="9465">,</TOKEN>
<TOKEN id="token-83-12" pos="word" morph="none" start_char="9467" end_char="9473">Belgium</TOKEN>
<TOKEN id="token-83-13" pos="punct" morph="none" start_char="9474" end_char="9474">,</TOKEN>
<TOKEN id="token-83-14" pos="word" morph="none" start_char="9476" end_char="9478">and</TOKEN>
<TOKEN id="token-83-15" pos="word" morph="none" start_char="9480" end_char="9486">Germany</TOKEN>
<TOKEN id="token-83-16" pos="punct" morph="none" start_char="9487" end_char="9487">.</TOKEN>
</SEG>
<SEG id="segment-84" start_char="9489" end_char="9610">
<ORIGINAL_TEXT>Once candidate vaccines are available, researchers will test them in animals, then seek approval for phase I human trials.</ORIGINAL_TEXT>
<TOKEN id="token-84-0" pos="word" morph="none" start_char="9489" end_char="9492">Once</TOKEN>
<TOKEN id="token-84-1" pos="word" morph="none" start_char="9494" end_char="9502">candidate</TOKEN>
<TOKEN id="token-84-2" pos="word" morph="none" start_char="9504" end_char="9511">vaccines</TOKEN>
<TOKEN id="token-84-3" pos="word" morph="none" start_char="9513" end_char="9515">are</TOKEN>
<TOKEN id="token-84-4" pos="word" morph="none" start_char="9517" end_char="9525">available</TOKEN>
<TOKEN id="token-84-5" pos="punct" morph="none" start_char="9526" end_char="9526">,</TOKEN>
<TOKEN id="token-84-6" pos="word" morph="none" start_char="9528" end_char="9538">researchers</TOKEN>
<TOKEN id="token-84-7" pos="word" morph="none" start_char="9540" end_char="9543">will</TOKEN>
<TOKEN id="token-84-8" pos="word" morph="none" start_char="9545" end_char="9548">test</TOKEN>
<TOKEN id="token-84-9" pos="word" morph="none" start_char="9550" end_char="9553">them</TOKEN>
<TOKEN id="token-84-10" pos="word" morph="none" start_char="9555" end_char="9556">in</TOKEN>
<TOKEN id="token-84-11" pos="word" morph="none" start_char="9558" end_char="9564">animals</TOKEN>
<TOKEN id="token-84-12" pos="punct" morph="none" start_char="9565" end_char="9565">,</TOKEN>
<TOKEN id="token-84-13" pos="word" morph="none" start_char="9567" end_char="9570">then</TOKEN>
<TOKEN id="token-84-14" pos="word" morph="none" start_char="9572" end_char="9575">seek</TOKEN>
<TOKEN id="token-84-15" pos="word" morph="none" start_char="9577" end_char="9584">approval</TOKEN>
<TOKEN id="token-84-16" pos="word" morph="none" start_char="9586" end_char="9588">for</TOKEN>
<TOKEN id="token-84-17" pos="word" morph="none" start_char="9590" end_char="9594">phase</TOKEN>
<TOKEN id="token-84-18" pos="word" morph="none" start_char="9596" end_char="9596">I</TOKEN>
<TOKEN id="token-84-19" pos="word" morph="none" start_char="9598" end_char="9602">human</TOKEN>
<TOKEN id="token-84-20" pos="word" morph="none" start_char="9604" end_char="9609">trials</TOKEN>
<TOKEN id="token-84-21" pos="punct" morph="none" start_char="9610" end_char="9610">.</TOKEN>
</SEG>
<SEG id="segment-85" start_char="9612" end_char="9685">
<ORIGINAL_TEXT>"We're building the airplane as we're flying," says Inovio CEO Joseph Kim.</ORIGINAL_TEXT>
<TOKEN id="token-85-0" pos="punct" morph="none" start_char="9612" end_char="9612">"</TOKEN>
<TOKEN id="token-85-1" pos="word" morph="none" start_char="9613" end_char="9617">We're</TOKEN>
<TOKEN id="token-85-2" pos="word" morph="none" start_char="9619" end_char="9626">building</TOKEN>
<TOKEN id="token-85-3" pos="word" morph="none" start_char="9628" end_char="9630">the</TOKEN>
<TOKEN id="token-85-4" pos="word" morph="none" start_char="9632" end_char="9639">airplane</TOKEN>
<TOKEN id="token-85-5" pos="word" morph="none" start_char="9641" end_char="9642">as</TOKEN>
<TOKEN id="token-85-6" pos="word" morph="none" start_char="9644" end_char="9648">we're</TOKEN>
<TOKEN id="token-85-7" pos="word" morph="none" start_char="9650" end_char="9655">flying</TOKEN>
<TOKEN id="token-85-8" pos="punct" morph="none" start_char="9656" end_char="9657">,"</TOKEN>
<TOKEN id="token-85-9" pos="word" morph="none" start_char="9659" end_char="9662">says</TOKEN>
<TOKEN id="token-85-10" pos="word" morph="none" start_char="9664" end_char="9669">Inovio</TOKEN>
<TOKEN id="token-85-11" pos="word" morph="none" start_char="9671" end_char="9673">CEO</TOKEN>
<TOKEN id="token-85-12" pos="word" morph="none" start_char="9675" end_char="9680">Joseph</TOKEN>
<TOKEN id="token-85-13" pos="word" morph="none" start_char="9682" end_char="9684">Kim</TOKEN>
<TOKEN id="token-85-14" pos="punct" morph="none" start_char="9685" end_char="9685">.</TOKEN>
</SEG>
<SEG id="segment-86" start_char="9688" end_char="9797">
<ORIGINAL_TEXT>NIAID Director Anthony Fauci says the first clinical trial of the Moderna vaccine could start within 3 months.</ORIGINAL_TEXT>
<TOKEN id="token-86-0" pos="word" morph="none" start_char="9688" end_char="9692">NIAID</TOKEN>
<TOKEN id="token-86-1" pos="word" morph="none" start_char="9694" end_char="9701">Director</TOKEN>
<TOKEN id="token-86-2" pos="word" morph="none" start_char="9703" end_char="9709">Anthony</TOKEN>
<TOKEN id="token-86-3" pos="word" morph="none" start_char="9711" end_char="9715">Fauci</TOKEN>
<TOKEN id="token-86-4" pos="word" morph="none" start_char="9717" end_char="9720">says</TOKEN>
<TOKEN id="token-86-5" pos="word" morph="none" start_char="9722" end_char="9724">the</TOKEN>
<TOKEN id="token-86-6" pos="word" morph="none" start_char="9726" end_char="9730">first</TOKEN>
<TOKEN id="token-86-7" pos="word" morph="none" start_char="9732" end_char="9739">clinical</TOKEN>
<TOKEN id="token-86-8" pos="word" morph="none" start_char="9741" end_char="9745">trial</TOKEN>
<TOKEN id="token-86-9" pos="word" morph="none" start_char="9747" end_char="9748">of</TOKEN>
<TOKEN id="token-86-10" pos="word" morph="none" start_char="9750" end_char="9752">the</TOKEN>
<TOKEN id="token-86-11" pos="word" morph="none" start_char="9754" end_char="9760">Moderna</TOKEN>
<TOKEN id="token-86-12" pos="word" morph="none" start_char="9762" end_char="9768">vaccine</TOKEN>
<TOKEN id="token-86-13" pos="word" morph="none" start_char="9770" end_char="9774">could</TOKEN>
<TOKEN id="token-86-14" pos="word" morph="none" start_char="9776" end_char="9780">start</TOKEN>
<TOKEN id="token-86-15" pos="word" morph="none" start_char="9782" end_char="9787">within</TOKEN>
<TOKEN id="token-86-16" pos="word" morph="none" start_char="9789" end_char="9789">3</TOKEN>
<TOKEN id="token-86-17" pos="word" morph="none" start_char="9791" end_char="9796">months</TOKEN>
<TOKEN id="token-86-18" pos="punct" morph="none" start_char="9797" end_char="9797">.</TOKEN>
</SEG>
<SEG id="segment-87" start_char="9799" end_char="9971">
<ORIGINAL_TEXT>In the best-case scenario, Barney Graham, who leads the project for NIAID, says the Moderna vaccine could be ready for larger, real-world efficacy tests in humans by summer.</ORIGINAL_TEXT>
<TOKEN id="token-87-0" pos="word" morph="none" start_char="9799" end_char="9800">In</TOKEN>
<TOKEN id="token-87-1" pos="word" morph="none" start_char="9802" end_char="9804">the</TOKEN>
<TOKEN id="token-87-2" pos="unknown" morph="none" start_char="9806" end_char="9814">best-case</TOKEN>
<TOKEN id="token-87-3" pos="word" morph="none" start_char="9816" end_char="9823">scenario</TOKEN>
<TOKEN id="token-87-4" pos="punct" morph="none" start_char="9824" end_char="9824">,</TOKEN>
<TOKEN id="token-87-5" pos="word" morph="none" start_char="9826" end_char="9831">Barney</TOKEN>
<TOKEN id="token-87-6" pos="word" morph="none" start_char="9833" end_char="9838">Graham</TOKEN>
<TOKEN id="token-87-7" pos="punct" morph="none" start_char="9839" end_char="9839">,</TOKEN>
<TOKEN id="token-87-8" pos="word" morph="none" start_char="9841" end_char="9843">who</TOKEN>
<TOKEN id="token-87-9" pos="word" morph="none" start_char="9845" end_char="9849">leads</TOKEN>
<TOKEN id="token-87-10" pos="word" morph="none" start_char="9851" end_char="9853">the</TOKEN>
<TOKEN id="token-87-11" pos="word" morph="none" start_char="9855" end_char="9861">project</TOKEN>
<TOKEN id="token-87-12" pos="word" morph="none" start_char="9863" end_char="9865">for</TOKEN>
<TOKEN id="token-87-13" pos="word" morph="none" start_char="9867" end_char="9871">NIAID</TOKEN>
<TOKEN id="token-87-14" pos="punct" morph="none" start_char="9872" end_char="9872">,</TOKEN>
<TOKEN id="token-87-15" pos="word" morph="none" start_char="9874" end_char="9877">says</TOKEN>
<TOKEN id="token-87-16" pos="word" morph="none" start_char="9879" end_char="9881">the</TOKEN>
<TOKEN id="token-87-17" pos="word" morph="none" start_char="9883" end_char="9889">Moderna</TOKEN>
<TOKEN id="token-87-18" pos="word" morph="none" start_char="9891" end_char="9897">vaccine</TOKEN>
<TOKEN id="token-87-19" pos="word" morph="none" start_char="9899" end_char="9903">could</TOKEN>
<TOKEN id="token-87-20" pos="word" morph="none" start_char="9905" end_char="9906">be</TOKEN>
<TOKEN id="token-87-21" pos="word" morph="none" start_char="9908" end_char="9912">ready</TOKEN>
<TOKEN id="token-87-22" pos="word" morph="none" start_char="9914" end_char="9916">for</TOKEN>
<TOKEN id="token-87-23" pos="word" morph="none" start_char="9918" end_char="9923">larger</TOKEN>
<TOKEN id="token-87-24" pos="punct" morph="none" start_char="9924" end_char="9924">,</TOKEN>
<TOKEN id="token-87-25" pos="unknown" morph="none" start_char="9926" end_char="9935">real-world</TOKEN>
<TOKEN id="token-87-26" pos="word" morph="none" start_char="9937" end_char="9944">efficacy</TOKEN>
<TOKEN id="token-87-27" pos="word" morph="none" start_char="9946" end_char="9950">tests</TOKEN>
<TOKEN id="token-87-28" pos="word" morph="none" start_char="9952" end_char="9953">in</TOKEN>
<TOKEN id="token-87-29" pos="word" morph="none" start_char="9955" end_char="9960">humans</TOKEN>
<TOKEN id="token-87-30" pos="word" morph="none" start_char="9962" end_char="9963">by</TOKEN>
<TOKEN id="token-87-31" pos="word" morph="none" start_char="9965" end_char="9970">summer</TOKEN>
<TOKEN id="token-87-32" pos="punct" morph="none" start_char="9971" end_char="9971">.</TOKEN>
</SEG>
<SEG id="segment-88" start_char="9973" end_char="10068">
<ORIGINAL_TEXT>Even if it works, mass-producing it or any other vaccine quickly would present a huge challenge.</ORIGINAL_TEXT>
<TOKEN id="token-88-0" pos="word" morph="none" start_char="9973" end_char="9976">Even</TOKEN>
<TOKEN id="token-88-1" pos="word" morph="none" start_char="9978" end_char="9979">if</TOKEN>
<TOKEN id="token-88-2" pos="word" morph="none" start_char="9981" end_char="9982">it</TOKEN>
<TOKEN id="token-88-3" pos="word" morph="none" start_char="9984" end_char="9988">works</TOKEN>
<TOKEN id="token-88-4" pos="punct" morph="none" start_char="9989" end_char="9989">,</TOKEN>
<TOKEN id="token-88-5" pos="unknown" morph="none" start_char="9991" end_char="10004">mass-producing</TOKEN>
<TOKEN id="token-88-6" pos="word" morph="none" start_char="10006" end_char="10007">it</TOKEN>
<TOKEN id="token-88-7" pos="word" morph="none" start_char="10009" end_char="10010">or</TOKEN>
<TOKEN id="token-88-8" pos="word" morph="none" start_char="10012" end_char="10014">any</TOKEN>
<TOKEN id="token-88-9" pos="word" morph="none" start_char="10016" end_char="10020">other</TOKEN>
<TOKEN id="token-88-10" pos="word" morph="none" start_char="10022" end_char="10028">vaccine</TOKEN>
<TOKEN id="token-88-11" pos="word" morph="none" start_char="10030" end_char="10036">quickly</TOKEN>
<TOKEN id="token-88-12" pos="word" morph="none" start_char="10038" end_char="10042">would</TOKEN>
<TOKEN id="token-88-13" pos="word" morph="none" start_char="10044" end_char="10050">present</TOKEN>
<TOKEN id="token-88-14" pos="word" morph="none" start_char="10052" end_char="10052">a</TOKEN>
<TOKEN id="token-88-15" pos="word" morph="none" start_char="10054" end_char="10057">huge</TOKEN>
<TOKEN id="token-88-16" pos="word" morph="none" start_char="10059" end_char="10067">challenge</TOKEN>
<TOKEN id="token-88-17" pos="punct" morph="none" start_char="10068" end_char="10068">.</TOKEN>
</SEG>
<SEG id="segment-89" start_char="10071" end_char="10181">
<ORIGINAL_TEXT>With luck, however, the outbreak will fade by summer, and with it the urgency of having a vaccine at the ready.</ORIGINAL_TEXT>
<TOKEN id="token-89-0" pos="word" morph="none" start_char="10071" end_char="10074">With</TOKEN>
<TOKEN id="token-89-1" pos="word" morph="none" start_char="10076" end_char="10079">luck</TOKEN>
<TOKEN id="token-89-2" pos="punct" morph="none" start_char="10080" end_char="10080">,</TOKEN>
<TOKEN id="token-89-3" pos="word" morph="none" start_char="10082" end_char="10088">however</TOKEN>
<TOKEN id="token-89-4" pos="punct" morph="none" start_char="10089" end_char="10089">,</TOKEN>
<TOKEN id="token-89-5" pos="word" morph="none" start_char="10091" end_char="10093">the</TOKEN>
<TOKEN id="token-89-6" pos="word" morph="none" start_char="10095" end_char="10102">outbreak</TOKEN>
<TOKEN id="token-89-7" pos="word" morph="none" start_char="10104" end_char="10107">will</TOKEN>
<TOKEN id="token-89-8" pos="word" morph="none" start_char="10109" end_char="10112">fade</TOKEN>
<TOKEN id="token-89-9" pos="word" morph="none" start_char="10114" end_char="10115">by</TOKEN>
<TOKEN id="token-89-10" pos="word" morph="none" start_char="10117" end_char="10122">summer</TOKEN>
<TOKEN id="token-89-11" pos="punct" morph="none" start_char="10123" end_char="10123">,</TOKEN>
<TOKEN id="token-89-12" pos="word" morph="none" start_char="10125" end_char="10127">and</TOKEN>
<TOKEN id="token-89-13" pos="word" morph="none" start_char="10129" end_char="10132">with</TOKEN>
<TOKEN id="token-89-14" pos="word" morph="none" start_char="10134" end_char="10135">it</TOKEN>
<TOKEN id="token-89-15" pos="word" morph="none" start_char="10137" end_char="10139">the</TOKEN>
<TOKEN id="token-89-16" pos="word" morph="none" start_char="10141" end_char="10147">urgency</TOKEN>
<TOKEN id="token-89-17" pos="word" morph="none" start_char="10149" end_char="10150">of</TOKEN>
<TOKEN id="token-89-18" pos="word" morph="none" start_char="10152" end_char="10157">having</TOKEN>
<TOKEN id="token-89-19" pos="word" morph="none" start_char="10159" end_char="10159">a</TOKEN>
<TOKEN id="token-89-20" pos="word" morph="none" start_char="10161" end_char="10167">vaccine</TOKEN>
<TOKEN id="token-89-21" pos="word" morph="none" start_char="10169" end_char="10170">at</TOKEN>
<TOKEN id="token-89-22" pos="word" morph="none" start_char="10172" end_char="10174">the</TOKEN>
<TOKEN id="token-89-23" pos="word" morph="none" start_char="10176" end_char="10180">ready</TOKEN>
<TOKEN id="token-89-24" pos="punct" morph="none" start_char="10181" end_char="10181">.</TOKEN>
</SEG>
<SEG id="segment-90" start_char="10183" end_char="10257">
<ORIGINAL_TEXT>"Nobody knows what's going to happen," says Stéphane Bancel, Moderna's CEO.</ORIGINAL_TEXT>
<TOKEN id="token-90-0" pos="punct" morph="none" start_char="10183" end_char="10183">"</TOKEN>
<TOKEN id="token-90-1" pos="word" morph="none" start_char="10184" end_char="10189">Nobody</TOKEN>
<TOKEN id="token-90-2" pos="word" morph="none" start_char="10191" end_char="10195">knows</TOKEN>
<TOKEN id="token-90-3" pos="word" morph="none" start_char="10197" end_char="10202">what's</TOKEN>
<TOKEN id="token-90-4" pos="word" morph="none" start_char="10204" end_char="10208">going</TOKEN>
<TOKEN id="token-90-5" pos="word" morph="none" start_char="10210" end_char="10211">to</TOKEN>
<TOKEN id="token-90-6" pos="word" morph="none" start_char="10213" end_char="10218">happen</TOKEN>
<TOKEN id="token-90-7" pos="punct" morph="none" start_char="10219" end_char="10220">,"</TOKEN>
<TOKEN id="token-90-8" pos="word" morph="none" start_char="10222" end_char="10225">says</TOKEN>
<TOKEN id="token-90-9" pos="word" morph="none" start_char="10227" end_char="10234">Stéphane</TOKEN>
<TOKEN id="token-90-10" pos="word" morph="none" start_char="10236" end_char="10241">Bancel</TOKEN>
<TOKEN id="token-90-11" pos="punct" morph="none" start_char="10242" end_char="10242">,</TOKEN>
<TOKEN id="token-90-12" pos="word" morph="none" start_char="10244" end_char="10252">Moderna's</TOKEN>
<TOKEN id="token-90-13" pos="word" morph="none" start_char="10254" end_char="10256">CEO</TOKEN>
<TOKEN id="token-90-14" pos="punct" morph="none" start_char="10257" end_char="10257">.</TOKEN>
</SEG>
<SEG id="segment-91" start_char="10259" end_char="10307">
<ORIGINAL_TEXT>"We're all hoping we'll never need this vaccine."</ORIGINAL_TEXT>
<TOKEN id="token-91-0" pos="punct" morph="none" start_char="10259" end_char="10259">"</TOKEN>
<TOKEN id="token-91-1" pos="word" morph="none" start_char="10260" end_char="10264">We're</TOKEN>
<TOKEN id="token-91-2" pos="word" morph="none" start_char="10266" end_char="10268">all</TOKEN>
<TOKEN id="token-91-3" pos="word" morph="none" start_char="10270" end_char="10275">hoping</TOKEN>
<TOKEN id="token-91-4" pos="word" morph="none" start_char="10277" end_char="10281">we'll</TOKEN>
<TOKEN id="token-91-5" pos="word" morph="none" start_char="10283" end_char="10287">never</TOKEN>
<TOKEN id="token-91-6" pos="word" morph="none" start_char="10289" end_char="10292">need</TOKEN>
<TOKEN id="token-91-7" pos="word" morph="none" start_char="10294" end_char="10297">this</TOKEN>
<TOKEN id="token-91-8" pos="word" morph="none" start_char="10299" end_char="10305">vaccine</TOKEN>
<TOKEN id="token-91-9" pos="punct" morph="none" start_char="10306" end_char="10307">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
